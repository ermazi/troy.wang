'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/docs/kubernetes/','title':"Kubernetes",'content':""});index.add({'id':1,'href':'/docs/kubernetes/posts/argo-rollouts-support-traefik/','title':"argo-rollouts之流量管理添加traefik支持",'content':"argo-rollouts之流量管理添加traefik支持 背景 在使用argo-rollouts做金丝雀部署的时候，为了精准控制流量，使用它流量控制的特性，该特性需要结合ingress网关一起作用，目前官网仅支持Nginx,Istio,ALB，而笔者使用最多的是traefik。\n最小化原则，最好在不改变现有基础设施的前提下用上argo-rollouts，所以被迫添加对traefik的支持。\ntraefik可行性验证 参考文档traefik分流，我们可以通过annotation的控制实现。\n结合argo-rollouts以及traefik文档，我们需要准备的资源对象如下：\n app-rollout || Rollout app-stable-service || Service app-canary-service || Service app-stable-ingress || Ingress  traefik带权重控制的Ingress配置：\napiVersion: extensions/v1beta1 kind: Ingress metadata: annotations: kubernetes.io/ingress.class: traefik traefik.ingress.kubernetes.io/service-weights: | app-stable-service: 100% app-canary-service: 0% name: app-stable-ingress spec: rules: - http: paths: - backend: serviceName: app-stable-service servicePort: 80 path: / - backend: serviceName: app-canary-service servicePort: 80 path: / 对比nginx的流量控制，nginx采用两个ingress进行weighted负载均衡，而traefik采用一个ingress进行weighted负载均衡；所以在argo-rollouts的流量控制实现上，我们只需要去将目标ingress的annotation设置为上述目标ingress即可.  代码分析 type TrafficRoutingReconciler interface { Reconcile(desiredWeight int32) error Type() string } 这是流量控制的接口，我们只需要实现Reconcile方法和Type即可，传入目标权重值，将权重渲染到对应的ingress资源模板中应用即可。\n关键代码 // 检查stable ingress func (r *Reconciler) checkStableIngress(stableIngress *extensionsv1beta1.Ingress) (err error) { stableServiceName := r.cfg.Rollout.Spec.Strategy.Canary.StableService canaryServiceName := r.cfg.Rollout.Spec.Strategy.Canary.CanaryService // 检查现有ingress配置中的services，保证相同host下的相同path下  // 的stableService和canaryService成对出现 \trules := stableIngress.Spec.Rules for _, rule := range rules { paths := rule.HTTP.Paths matchMap := make(map[string]int) for _, path := range paths { if path.Backend.ServiceName == stableServiceName { matchMap[path.Path]++ } else if path.Backend.ServiceName == canaryServiceName { matchMap[path.Path]++ } } for p, cnt := range matchMap { if cnt == 1 { err = fmt.Errorf(\u0026#34;[host/path: %s/%s] stableService %s and canaryService %s must be consistent\u0026#34;, rule.Host, p, stableServiceName, canaryServiceName) r.log.WithField(logutil.IngressKey, stableIngress). WithField(\u0026#34;host/path\u0026#34;, rule.Host + \u0026#34;/\u0026#34; + p).WithError(err) return } } } return } // 协调traefik的ingress设定为指定权重的状态 func (r *Reconciler) Reconcile(desiredWeight int32) error { // 获取stableIngress \tstableIngressName := r.cfg.Rollout.Spec.Strategy.Canary.TrafficRouting.Traefik.StableIngress stableIngress, err := r.cfg.IngressLister.Ingresses(r.cfg.Rollout.Namespace).Get(stableIngressName) if err != nil { r.log.WithField(logutil.IngressKey, stableIngressName).WithField(\u0026#34;err\u0026#34;, err.Error()).Error(\u0026#34;error retrieving stableIngress\u0026#34;) return fmt.Errorf(\u0026#34;error retrieving stableIngress `%s` from cache: %v\u0026#34;, stableIngressName, err) } // 校验流程 \terr = r.checkStableIngress(stableIngress) if err != nil { r.cfg.Recorder.Event(r.cfg.Rollout, corev1.EventTypeWarning, \u0026#34;CheckIngress\u0026#34;, fmt.Sprintf(\u0026#34;checkc ingress `%s` failed, with error `%s`\u0026#34;, stableIngressName, err.Error())) return err } // 插入权重的annotation设定 \tif _, ok := stableIngress.GetAnnotations()[\u0026#34;traefik.ingress.kubernetes.io/service-weights\u0026#34;]; !ok { stableIngress.GetAnnotations()[\u0026#34;traefik.ingress.kubernetes.io/service-weights\u0026#34;] = r.getAnnotationWeightConfig(desiredWeight) _, err = r.cfg.Client.ExtensionsV1beta1().Ingresses(r.cfg.Rollout.Namespace).Update(stableIngress) if err != nil { r.log.WithField(logutil.IngressKey, stableIngressName).Error(err.Error()) r.cfg.Recorder.Event(r.cfg.Rollout, corev1.EventTypeNormal, \u0026#34;InitIngressAnnotation\u0026#34;, fmt.Sprintf(\u0026#34;init ingress [%s] annotation`%s` success\u0026#34;, stableIngressName)) return err } } // 更新期望weights \tstableIngress.Annotations[\u0026#34;traefik.ingress.kubernetes.io/service-weights\u0026#34;] = r.getAnnotationWeightConfig(desiredWeight) r.log.WithField(logutil.IngressKey, stableIngressName).Infof(\u0026#34;adjust ingress %s weight, [canaryService: %d] success\u0026#34;, stableIngressName, desiredWeight) _, err = r.cfg.Client.ExtensionsV1beta1().Ingresses(r.cfg.Rollout.Namespace).Update(stableIngress) if err != nil { r.log.WithField(logutil.IngressKey, stableIngressName).Errorf(\u0026#34;fail to adjust ingress %s weight, err: %s\u0026#34;, stableIngressName, err.Error()) r.cfg.Recorder.Event(r.cfg.Rollout, corev1.EventTypeWarning, \u0026#34;AdjustIngressWeight\u0026#34;, fmt.Sprintf(\u0026#34;fail to adjust ingress %s weight, err: %s\u0026#34;, stableIngressName, err.Error())) return err } return nil } // 渲染ingress模板 func (r *Reconciler) getAnnotationWeightConfig(desiredWeight int32) string { stableServiceName := r.cfg.Rollout.Spec.Strategy.Canary.StableService canaryServiceName := r.cfg.Rollout.Spec.Strategy.Canary.CanaryService return fmt.Sprintf(`{\u0026#34;%s\u0026#34;: %d,\u0026#34;%s\u0026#34;: %d}`,stableServiceName, 100 - desiredWeight,canaryServiceName, desiredWeight) } 验证 验证的用例包括：\n 金丝雀发布功能：发布，暂停，回滚，promote 流量是否按照既定weight进行分流 切换过程中是否平滑安全  验证使用的rollout配置：\napiVersion: argoproj.io/v1alpha1 kind: Rollout metadata: name: app-rollout spec: replicas: 5 selector: matchLabels: app: nginx strategy: canary: canaryService: app-canary-service stableService: app-stable-service steps: - setWeight: 10 - pause: {} trafficRouting: traefik: stableIngress: app-ingress template: metadata: labels: app: nginx spec: containers: - image: nginx:v1.14.2 name: nginx ports: - containerPort: 80 name: http resources: {} readinessProbe: failureThreshold: 3 httpGet: path: / port: http scheme: HTTP initialDelaySeconds: 10 periodSeconds: 5 successThreshold: 1 timeoutSeconds: 2 livenessProbe: failureThreshold: 2 httpGet: path: / port: http scheme: HTTP initialDelaySeconds: 5 periodSeconds: 5 successThreshold: 1 timeoutSeconds: 2 lifecycle: preStop: exec: command: [\u0026#34;sleep\u0026#34;, \u0026#34;5s\u0026#34;] 验证实验就省略罗，关键Rollout已经给出，操作命令见上一篇。  等待上线 "});index.add({'id':2,'href':'/docs/golang/posts/golang-gateway/','title':"golang实现简单网关",'content':"golang实现简单网关  网关=反向代理+负载均衡+各种策略，技术实现也有多种多样，有基于nginx使用lua的实现，比如openresty、kong；也有基于zuul的通用网关；还有就是golang的网关，比如tyk。\n这篇文章主要是讲如何基于golang实现一个简单的网关。\n 1. 预备 1.1. 准备两个后端web服务 启动两个后端web服务（代码） type RealServer struct { Addr string } func (r *RealServer) Run() { log.Println(\u0026#34;start http server at \u0026#34; + r.Addr) mux := http.NewServeMux() mux.HandleFunc(\u0026#34;/\u0026#34;, r.EchoHandler) mux.HandleFunc(\u0026#34;/base/error\u0026#34;, r.ErrorHandler) mux.HandleFunc(\u0026#34;/timeout\u0026#34;, r.TimeoutHandler) server := \u0026amp;http.Server{ Addr: r.Addr, WriteTimeout: time.Second * 3, Handler: mux, } go func() { log.Fatal(server.ListenAndServe()) }() } func (r *RealServer) EchoHandler(w http.ResponseWriter, req *http.Request) { upath := fmt.Sprintf(\u0026#34;http://%s%s\\n\u0026#34;, r.Addr, req.URL.Path) realIP := fmt.Sprintf(\u0026#34;RemoteAddr=%s,X-Forwarded-For=%v,X-Real-Ip=%v\\n\u0026#34;, req.RemoteAddr, req.Header.Get(\u0026#34;X-Forwarded-For\u0026#34;), req.Header.Get(\u0026#34;X-Real-Ip\u0026#34;)) header := fmt.Sprintf(\u0026#34;headers =%v\\n\u0026#34;, req.Header) io.WriteString(w, upath) io.WriteString(w, realIP) io.WriteString(w, header) } func (r *RealServer) ErrorHandler(w http.ResponseWriter, req *http.Request) { w.WriteHeader(500) io.WriteString(w, \u0026#34;error handler\u0026#34;) } func (r *RealServer) TimeoutHandler(w http.ResponseWriter, req *http.Request) { time.Sleep(6 * time.Second) w.WriteHeader(200) io.WriteString(w, \u0026#34;timeout handler\u0026#34;) } func main() { rs1 := \u0026amp;RealServer{Addr: \u0026#34;127.0.0.1:2003\u0026#34;} rs1.Run() rs2 := \u0026amp;RealServer{Addr: \u0026#34;127.0.0.1:2004\u0026#34;} rs2.Run() quit := make(chan os.Signal) signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM) \u0026lt;-quit }    1.2. 访问工具 这里使用命令行工具进行测试\ncurl -v http://localhost:2002/base 2. 反向代理 2.1. 单后端（target）反向代理 具体代码 package main import ( \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;net/http/httputil\u0026#34; \u0026#34;net/url\u0026#34; ) var ( addr = \u0026#34;127.0.0.1:2002\u0026#34; ) func main() { rsUrl, _:=url.Parse(\u0026#34;http://127.0.0.1:2003/base\u0026#34;) reversePorxy := httputil.NewSingleHostReverseProxy(rsUrl) log.Println(\u0026#34;Starting Httpserver at \u0026#34; + addr) log.Fatal(http.ListenAndServe(addr, reversePorxy)) } 直接使用基础库httputil提供的NewSingleHostReverseProxy即可，返回的reverseProxy对象实现了serveHttp方法，因此可以直接作为handler。\n  2.2. 分析反向代理代码，并添加修改response内容 具体代码 package main import ( \u0026#34;bytes\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;net/http/httputil\u0026#34; \u0026#34;net/url\u0026#34; \u0026#34;strings\u0026#34; ) var ( addr = \u0026#34;127.0.0.1:2002\u0026#34; ) func main() { rsUrl, _:=url.Parse(\u0026#34;http://127.0.0.1:2003/base\u0026#34;) reversePorxy := NewSingleHostReverseProxy(rsUrl) log.Println(\u0026#34;Starting httpserver at \u0026#34; + addr) log.Fatal(http.ListenAndServe(addr, reversePorxy)) } func NewSingleHostReverseProxy(target *url.URL) *httputil.ReverseProxy { targetQuery := target.RawQuery director := func(req *http.Request) { req.URL.Scheme = target.Scheme req.URL.Host = target.Host req.URL.Path = singleJoiningSlash(target.Path, req.URL.Path) if targetQuery == \u0026#34;\u0026#34; || req.URL.RawQuery == \u0026#34;\u0026#34; { req.URL.RawQuery = targetQuery + req.URL.RawQuery } else { req.URL.RawQuery = targetQuery + \u0026#34;\u0026amp;\u0026#34; + req.URL.RawQuery } if _, ok := req.Header[\u0026#34;User-Agent\u0026#34;]; !ok { // explicitly disable User-Agent so it\u0026#39;s not set to default value \treq.Header.Set(\u0026#34;User-Agent\u0026#34;, \u0026#34;\u0026#34;) } // add when the reverseproxy is the first rp \treq.Header.Set(\u0026#34;X-Real-Ip\u0026#34;, strings.Split(req.RemoteAddr, \u0026#34;:\u0026#34;)[0]) } modifyFunc := func(res *http.Response) error { if res.StatusCode != http.StatusOK { oldPayLoad, err := ioutil.ReadAll(res.Body) if err != nil { return err } newPayLoad := []byte(\u0026#34;hello \u0026#34; + string(oldPayLoad)) res.Body = ioutil.NopCloser(bytes.NewBuffer(newPayLoad)) res.ContentLength = int64(len(newPayLoad)) res.Header.Set(\u0026#34;Content-Length\u0026#34;,fmt.Sprint(len(newPayLoad))) } return nil } return \u0026amp;httputil.ReverseProxy{Director: director, ModifyResponse: modifyFunc} } func singleJoiningSlash(a, b string) string { aslash := strings.HasSuffix(a, \u0026#34;/\u0026#34;) bslash := strings.HasPrefix(b, \u0026#34;/\u0026#34;) switch { case aslash \u0026amp;\u0026amp; bslash: return a + b[1:] case !aslash \u0026amp;\u0026amp; !bslash: return a + \u0026#34;/\u0026#34; + b } return a + b }    director中定义回调函数，入参为*http.Request，决定如何构造向后端的请求，比如host是否向后传递，是否进行url重写，对于header的处理，后端target的选择等，都可以在这里完成。\ndirector在这里具体做了：\n 根据后端target，构造到后端请求的url 选择性传递必要的header 设置代理相关的header，比如X-Forwarded-For、X-Real-Ip  X-Forwarded-For记录经过的所有代理，以proxyIp01, proxyIp02, proxyIp03的格式记录，由于是追加，可能被篡改，当然，如果第一代理以覆盖该头的方式进行记录，也是可信的 X-Real-Ip用于记录客户端IP，一般放在第一代理上，用于记录客户端的来源公网IP，可信    modifyResponse中定义回调函数，入参为*http.Response，用于修改响应的信息，比如响应的Body，响应的Header等信息。\n最终依旧是返回一个ReverseProxy，然后将这个对象作为handler传入即可。\n2.3. 支持多个后端服务器 参考2.2 中的NewSingleHostReverseProxy，只需要实现一个类似的、支持多targets的方法即可，具体实现见后面。\n3. 负载均衡 作为一个网关服务，在上面2.3的基础上，需要支持必要的负载均衡策略，比如：\n 随机 轮询 加权轮询 一致性hash  3.1. 负载均衡算法 3.1.1. 随机 随便random一个整数作为索引，然后取对应的地址即可，实现比较简单。\n具体代码 type RandomN struct { rss []string } func (r *RandomN) Add(params ...string) error { if len(params) != 1 { return fmt.Errorf(\u0026#34;param length should be one\u0026#34;) } r.rss = append(r.rss, params[0]) return nil } func (r *RandomN) Next() string { if len(r.rss)\t== 0 { return \u0026#34;\u0026#34; } return r.rss[rand.Intn(len(r.rss))] } func (r *RandomN) Get(key string) (string, error) { return r.Next(), nil }    3.1.2. 轮询 使用curIndex进行累加计数，一旦超过rss数组的长度，则重置。\n具体代码 type RR struct { curIndex int rss []string } func (r *RR) Add(params ...string) error { if len(params) != 1 { return fmt.Errorf(\u0026#34;param length should be one\u0026#34;) } r.rss = append(r.rss, params[0]) return nil } func (r *RR) Next() string { if len(r.rss)\t== 0 { return \u0026#34;\u0026#34; } if r.curIndex == len(r.rss) { r.curIndex = 0 } node := r.rss[r.curIndex] r.curIndex++ return node } func (r *RR) Get(key string) (string, error) { return r.Next(), nil }    3.1.3. 加权轮询 轮询带权重，如果使用计数递减的方式，如果权重是5,1,1那么后端rs依次为a,a,a,a,a,b,c,a,a,a,a...，其中a后端会瞬间压力过大；参考nginx内部的加权轮询，或者应该称之为平滑加权轮询，思路是：\n后端真实节点包含三个权重：\n 本身权重weight —— 设置的权重 有效权重effectiveWeight —— 根据后端节点健康状态动态变化，当异常时，减一；当正常时，加一，最多到weight值 当前权重curWeight —— 初始值为weight，计算时curWeight += effectiveWeight，如果curWeight最大，则被选中，然后curWeight -= total  操作步骤：\n 计算curWeight 选取最大curWeight的节点 重新计算curWeight  具体代码 type WeightedRR struct { rss []*WeightedNode } type WeightedNode struct { addr string weight int curWeight int effectiveWeight int } func (r *WeightedRR) Add(params ...string) error { if len(params) != 2 { return fmt.Errorf(\u0026#34;param length should be two\u0026#34;) } addr := params[0] weight, err := strconv.ParseInt(params[1], 10, 64) if err != nil { return err } node := \u0026amp;WeightedNode{ addr: addr, weight: int(weight), curWeight: int(weight), effectiveWeight: int(weight), } r.rss = append(r.rss, node) return nil } func (r *WeightedRR) Next() string { // 平滑加权轮询 --\u0026gt; 1 计算total， 2 变更临时权重 3. 选择最大临时权重 4。 变更临时权重 \ttotal := 0 var best *WeightedNode for _, node := range r.rss { n := node total += n.effectiveWeight n.curWeight += n.effectiveWeight if best == nil || n.curWeight \u0026gt; best.curWeight { best = n } } if best == nil { return \u0026#34;\u0026#34; } best.curWeight -= total return best.addr } func (r *WeightedRR) Get(key string) (string, error) { return r.Next(), nil }    3.1.4. 一致性hash 一致性hash算法，主要是用于分布式cache热点/命中问题；这里用于基于某key的hash值，路由到固定后端，但是只能是基本满足流量绑定，一旦后端目标节点故障，会自动平移到环上最近的那么个节点。\n实现：\n  首先存在一个环，环上的每个点都能被选择的hash函数映射到\n  然后将后端真实节点+序号（副本数）映射到环上\n  当请求进来的时候，使用某特定组成的key代入hash函数计算得到一个位置\n 如果key是由url组成，那就是url hash 如果key是由remoteIp组成，那么就是IP hash    使用二分查找，找到其在环上的下一个节点\n  具体代码 type Keys []uint32 func (k Keys) Less(i, j int) bool { return k[i] \u0026lt; k[j] } func (k Keys) Swap(i, j int) { k[i], k[j] = k[j], k[i] } func (k Keys) Len() int { return len(k) } type ConsistentHash struct { mux sync.RWMutex hash func(data []byte) uint32 replicas int keys Keys hashMap map[uint32]string } func NewConsistentHash(replicas int, fn func(data []byte) uint32) *ConsistentHash { m := \u0026amp;ConsistentHash{ hash: fn, replicas: replicas, hashMap: make((map[uint32]string)), } if m.hash == nil { m.hash = crc32.ChecksumIEEE } return m } func (c *ConsistentHash) Add(params ...string) error { if len(params) == 0 { return errors.New(\u0026#34;param len 1 at least\u0026#34;) } addr := params[0] c.mux.Lock() defer c.mux.Unlock() for i := 0; i \u0026lt; c.replicas; i++ { hash := c.hash([]byte(strconv.Itoa(i) + addr)) c.keys = append(c.keys, hash) c.hashMap[hash] = addr } sort.Sort(c.keys) return nil } func (c *ConsistentHash) IsEmpty() bool { return len(c.keys) == 0 } func (c *ConsistentHash) Get(key string) (string, error) { if c.IsEmpty() { err := fmt.Errorf(\u0026#34;nodes empty\u0026#34;) return \u0026#34;\u0026#34;, err } hash := c.hash([]byte(key)) idx := sort.Search(len(c.keys), func(i int) bool { return c.keys[i] \u0026gt;= hash }) if idx == len(c.keys) { idx = 0 } return c.hashMap[c.keys[idx]], nil }    3.2. 通用接口/工厂模式 type LoadBalanceStrategy interface { Add(...string) error Get(string) (string, error) } 每一种不同的负载均衡算法，只需要实现添加以及获取的接口即可。\ntype LbType int const ( LbRandom LbType = iota LbRoundRobin LbWeightRoundRobin LbConsistentHash ) func LoadBanlanceFactory(lbType LbType) LoadBalanceStrategy { switch lbType { case LbRandom: return \u0026amp;RandomN{} case LbConsistentHash: return NewConsistentHash(10, nil) case LbRoundRobin: return \u0026amp;RR{} case LbWeightRoundRobin: return \u0026amp;WeightedRR{} default: return \u0026amp;RR{} } } 然后使用工厂方法，根据传入的参数，决定使用哪种负载均衡策略。\n3.3. 支持负载均衡算法的反向代理实现  使用LoadBanlanceFactory工厂函数，传入负载均衡类型，获取负载均衡对象 添加后端真实节点 然后初始化NewMultiTargetsReverseProxy，在director回调函数中，根据负载均衡策略获取要请求的后端真实节点 剩下的逻辑同2.2  具体代码 func NewMultiTargetsReverseProxy(lb lb_strategy.LoadBalanceStrategy) *httputil.ReverseProxy { director := func(req *http.Request) { remoteIP := strings.Split(req.RemoteAddr, \u0026#34;:\u0026#34;)[0] nextAddr, err := lb.Get(remoteIP) if err != nil { log.Fatal(\u0026#34;get next addr fail\u0026#34;) } target, err := url.Parse(nextAddr) if err != nil { log.Fatal(err) } targetQuery := target.RawQuery req.URL.Scheme = target.Scheme req.URL.Host = target.Host req.URL.Path = singleJoiningSlash(target.Path, req.URL.Path) if targetQuery == \u0026#34;\u0026#34; || req.URL.RawQuery == \u0026#34;\u0026#34; { req.URL.RawQuery = targetQuery + req.URL.RawQuery } else { req.URL.RawQuery = targetQuery + \u0026#34;\u0026amp;\u0026#34; + req.URL.RawQuery } if _, ok := req.Header[\u0026#34;User-Agent\u0026#34;]; !ok { req.Header.Set(\u0026#34;User-Agent\u0026#34;, \u0026#34;user-agent\u0026#34;) } } modifyFunc := func(resp *http.Response) error { //请求以下命令：curl \u0026#39;http://127.0.0.1:2002/error\u0026#39; \tif resp.StatusCode != 200 { //获取内容 \toldPayload, err := ioutil.ReadAll(resp.Body) if err != nil { return err } //追加内容 \tnewPayload := []byte(\u0026#34;StatusCode error:\u0026#34; + string(oldPayload)) resp.Body = ioutil.NopCloser(bytes.NewBuffer(newPayload)) resp.ContentLength = int64(len(newPayload)) resp.Header.Set(\u0026#34;Content-Length\u0026#34;, strconv.FormatInt(int64(len(newPayload)), 10)) } return nil } errFunc := func(w http.ResponseWriter, r *http.Request, err error) { //todo 如果是权重的负载则调整临时权重 \thttp.Error(w, \u0026#34;ErrorHandler error:\u0026#34;+err.Error(), 500) } return \u0026amp;httputil.ReverseProxy{Director: director, Transport: transport, ModifyResponse: modifyFunc, ErrorHandler: errFunc} } func singleJoiningSlash(a, b string) string { aslash := strings.HasSuffix(a, \u0026#34;/\u0026#34;) bslash := strings.HasPrefix(b, \u0026#34;/\u0026#34;) switch { case aslash \u0026amp;\u0026amp; bslash: return a + b[1:] case !aslash \u0026amp;\u0026amp; !bslash: return a + \u0026#34;/\u0026#34; + b } return a + b } func main() { rb := lb_strategy.LoadBanlanceFactory(lb_strategy.LbConsistentHash) rb.Add(\u0026#34;http://127.0.0.1:2003/base\u0026#34;) rb.Add(\u0026#34;http://127.0.0.1:2004/base\u0026#34;) rb.Add(\u0026#34;http://127.0.0.1:2005/base\u0026#34;) proxy := NewMultiTargetsReverseProxy(rb) log.Println(\u0026#34;Starting httpserver at \u0026#34; + addr) log.Fatal(http.ListenAndServe(addr, proxy)) }    4. 中间件 作为网关，中间件必不可少，这类包括请求响应的模式，一般称作洋葱模式，每一层都是中间件，一层层进去，然后一层层出来。\n中间件的实现一般有两种，一种是使用数组，然后配合index计数；一种是链式调用。\n4.1. 基于数组的中间件实现  NewSliceRouterHandler 获取SliceRouterHandler对象，该对象实现了Hanlder接口，可以作为handler传入http服务  ServeHTTP方法中，调用newSliceRouterContext初始化SliceRouterContext，并且根据req中的url，按照最长url前缀匹配的规则寻找groups中满足条件的SliceGroup丢给SliceRouterContext ServeHTTP方法中，调用Next方法开始整个handlers数组的handler调用   SliceRouterHandler包含coreFunc以及SliceRouter对象 SliceRouter包含SliceGroup列表 SliceGroup对象包含path以及handlers  使用Use方法来添加中间件，并且去重添加到SliceRouter中的groups中去 使用Group方法初始化一个SliceGroup   贯穿整条调用链的是SliceRouterContext对象，包含：  SliceGroup指针 ResponseWriter Request指针 Context index索引   中间件中可以调用SliceRouterContext中的Next方法继续，也可以调用Abort方法进行终止 Abort终止的方式就是设置索引index为abortIndex  具体代码 const abortIndex int8 = math.MaxInt8 / 2 type HandlerFunc func(*SliceRouterContext) type SliceRouter struct { groups []* SliceGroup } type SliceGroup struct { *SliceRouter path string handlers []HandlerFunc } // slice router context type SliceRouterContext struct { *SliceGroup RespW http.ResponseWriter Req *http.Request Ctx context.Context index int8 } func newSliceRouterContext(rw http.ResponseWriter, req *http.Request, r *SliceRouter) *SliceRouterContext { newSliceGroup := \u0026amp;SliceGroup{} matchUrlLen := 0 for _, group := range r.groups { if strings.HasPrefix(req.RequestURI, group.path) { pathLen := len(group.path) if pathLen \u0026gt; matchUrlLen { matchUrlLen = pathLen *newSliceGroup = *group //浅拷贝数组指针  } } } c := \u0026amp;SliceRouterContext{RespW: rw, Req: req, SliceGroup: newSliceGroup, Ctx: req.Context()} c.Reset() return c } // 获取上下文值 func (ctx *SliceRouterContext) Get(key interface{}) interface{} { return ctx.Ctx.Value(key) } // 设置上下文值 func (ctx *SliceRouterContext) Set(key, val interface{}) { ctx.Ctx = context.WithValue(ctx.Ctx, key, val) } // func (ctx *SliceRouterContext) Next() { ctx.index++ for ctx.index \u0026lt; int8(len(ctx.groups)) { ctx.handlers[ctx.index](ctx) ctx.index++ } } // 重置handlers数组计数 func (ctx *SliceRouterContext) Reset() { ctx.index = -1 } func (ctx *SliceRouterContext) Abort() { ctx.index = abortIndex } // 是否跳过了回调 func (ctx *SliceRouterContext) IsAborted() bool { return ctx.index \u0026gt;= abortIndex } // sliceRouterHandler type SliceRouterHandler struct { coreFunc func(*SliceRouterContext) http.Handler router *SliceRouter } func NewSliceRouterHandler(coreFunc func(*SliceRouterContext) http.Handler, router *SliceRouter) *SliceRouterHandler { return \u0026amp;SliceRouterHandler{ coreFunc: coreFunc, router: router, } } func (w *SliceRouterHandler) ServeHTTP(rw http.ResponseWriter, req *http.Request) { c := newSliceRouterContext(rw, req, w.router) if w.coreFunc != nil { c.handlers = append(c.handlers, func(c *SliceRouterContext) { w.coreFunc(c).ServeHTTP(rw, req) }) } c.Reset() c.Next() } // 构造 router func NewSliceRouter() *SliceRouter { return \u0026amp;SliceRouter{} } // 创建 Group func (g *SliceRouter) Group(path string) *SliceGroup { return \u0026amp;SliceGroup{ SliceRouter: g, path: path, } } // 构造回调方法 func (g *SliceGroup) Use(middlewares ...HandlerFunc) *SliceGroup { g.handlers = append(g.handlers, middlewares...) existsFlag := false for _, oldGroup := range g.SliceRouter.groups { if oldGroup == g { existsFlag = true } } if !existsFlag { g.SliceRouter.groups = append(g.SliceRouter.groups, g) } return g }    tracelog中间件 具体代码 func TraceLogSliceMiddleware() func(c *SliceRouterContext) { return func(c *SliceRouterContext) { log.Println(\u0026#34;trace_in\u0026#34;) c.Abort() log.Println(\u0026#34;trace_out\u0026#34;) } }    中间件使用 具体代码 var addr = \u0026#34;127.0.0.1:2002\u0026#34; func main() { reverseProxy := func(c *middleware.SliceRouterContext) http.Handler { rs1 := \u0026#34;http://127.0.0.1:2003/base\u0026#34; url1, err1 := url.Parse(rs1) if err1 != nil { log.Println(err1) } rs2 := \u0026#34;http://127.0.0.1:2004/base\u0026#34; url2, err2 := url.Parse(rs2) if err2 != nil { log.Println(err2) } urls := []*url.URL{url1, url2} return proxy.NewMultipleHostsReverseProxy(c, urls) } log.Println(\u0026#34;Starting httpserver at \u0026#34; + addr) sliceRouter := middleware.NewSliceRouter() sliceRouter.Group(\u0026#34;/base\u0026#34;).Use(middleware.TraceLogSliceMiddleware(), func(c *middleware.SliceRouterContext) { c.RespW.Write([]byte(\u0026#34;test func\u0026#34;)) }) sliceRouter.Group(\u0026#34;/\u0026#34;).Use(middleware.TraceLogSliceMiddleware(), func(c *middleware.SliceRouterContext) { fmt.Println(\u0026#34;reverseProxy\u0026#34;) reverseProxy(c).ServeHTTP(c.RespW, c.Req) }) routerHandler := middleware.NewSliceRouterHandler(nil, sliceRouter) log.Fatal(http.ListenAndServe(addr, routerHandler)) }    "});index.add({'id':3,'href':'/docs/kubernetes/posts/argo-rollouts/','title':"k8s灰度发布神器之argo-rollouts",'content':"k8s灰度发布工具之argo-rollouts  Kubernetes默认的Deployment资源支持两种发布策略：RollingUpdate和Recreate，这两个恶略可以满足大部分发布场景；但是针对于各种大规模的生产场景，需要额外的发布策略，比如蓝绿部署或者金丝雀部署。为了满足改需求，argo-rollouts应运而生。\n 背景 Recreate策略毫无平滑可言，通常用于仅可运行单副本的有状态应用/job。\nRollingUpdate策略，在完善的Pod生命周期前提下，能做到平滑。\n在生产持续部署过程中，多多少少会因为一些纰漏，导致新上线的应用出现问题；如果使用RollingUpdate，一旦下发指令，不可中断，直接影响全部流量，影响过大。\n要解决/缓解该问题，有几个努力方向：\n 尽可能完善的测试，减少问题 使用蓝绿部署，在新版本集中进行完善的测试；确认没问题后，切换流量到新版本 使用金丝雀部署，先更新部分副本，然后使用生产小流量（比如1%）进行验证，确认没问题之后，再缓慢放开，5% 20% 50% 100%  argo-rollouts咋工作的 跟Deployment对象类似，Rollout对象管理ReplicaSets。Rollout的spec.strategy字段决定发布如何从老的replicaSet变为新的replicaSet，期间可暂停，可继续，可发布更新的版本。假设三个阶段，分别对应三个replicaSets：stable、new、newer，当stable -\u0026gt; new时，当前处于desiredWeight/Paused状态：\n 如果newer发布，那么new -\u0026gt; 0，newer -\u0026gt; desiredWeight，stable -\u0026gt; newer 如果abort操作，那么new -\u0026gt; 0，stable -\u0026gt; max 如果promote操作，那么new -\u0026gt; max, stable -\u0026gt;0  argo-rollouts使用场景  用户想在生产环境基于新版本做最后一分钟的功能测试，那么可以使用蓝绿部署。本质就是两个Service的切换 用户想在线上流量进来之前，需要做一系列准备，比如预热，初始化等操作，那么可以使用蓝绿部署。在绿版本上完成相应的操作，然后再切换接收线上流量 用户想在生产环境使用小流量验证一段时间，确认稳定运行，没有Bug之后，再全量发布，那么可以使用金丝雀部署。小流量发布后，暂停验证，查看日志，观测应用指标，然后决定是回滚还是继续推进。 用户想慢慢的放进生产流量，那么可以使用金丝雀部署。定义多steps，慢慢调大权重 用户任性，说我不想用任何策略，就想滚动更新，那么也可以使用Rollout，将steps置空即可。  部署 集群级别部署argo rollouts $ kubectl apply -n argo-rollouts -f https://raw.githubusercontent.com/argoproj/argo-rollouts/stable/manifests/install.yaml 官方文档讲得挺详细的，自行摸索吧  安装kubectl插件 curl -LO https://github.com/argoproj/argo-rollouts/releases/latest/download/kubectl-argo-rollouts-darwin-amd64 chmod +x ./kubectl-argo-rollouts-darwin-amd64 sudo mv ./kubectl-argo-rollouts-darwin-amd64 /usr/local/bin/kubectl-argo-rollouts kubectl argo rollouts version 附录 常用命令 查看 kubectl argo rollouts list rollouts 中断回滚 kubectl argo rollouts abort app-rollout 继续发布 kubectl argo rollouts promote app-rollout  "});index.add({'id':4,'href':'/docs/golang/posts/circuit-breaker/','title':"hytrix-go",'content':"基于hytrix-go的熔断器  流量限制，熔断器，服务降级\n 1. 代码示例 package main import ( \u0026#34;errors\u0026#34; \u0026#34;github.com/afex/hystrix-go/hystrix\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; ) func main() { hystrixStreamHandler := hystrix.NewStreamHandler() hystrixStreamHandler.Start() go http.ListenAndServe(\u0026#34;:8074\u0026#34;, hystrixStreamHandler) hystrix.ConfigureCommand(\u0026#34;aaa\u0026#34;, hystrix.CommandConfig{ Timeout: 1000, // 单次请求 超时时间 \tMaxConcurrentRequests: 1, // 最大并发量 \tSleepWindow: 5000, // 熔断后多久去尝试服务是否可用 \tRequestVolumeThreshold: 1, ErrorPercentThreshold: 1, }) for i := 0; i \u0026lt; 10000; i++ { //异步调用使用 hystrix.Go \terr := hystrix.Do(\u0026#34;aaa\u0026#34;, func() error { //test case 1 并发测试 \tif i == 0 { return errors.New(\u0026#34;service error\u0026#34;) } //test case 2 超时测试 \t//time.Sleep(2 * time.Second) \tlog.Println(\u0026#34;do services\u0026#34;) return nil }, nil) if err != nil { log.Println(\u0026#34;hystrix err:\u0026#34; + err.Error()) time.Sleep(1 * time.Second) log.Println(\u0026#34;sleep 1 second\u0026#34;) } } time.Sleep(100 * time.Second) }  Timeout 单次请求的超时时间,超时进fallback MaxConcurrentRequests 最大并发量，这里是并发，并非QPS SleepWindow 熔断后sleep多久再次尝试服务是否可用 RequestVolumeThreshold 判断熔断的最少请求数，默认是10；只有在一个统计窗口内处理的请求数量达到这个阈值，才会进行熔断与否的判断 ErrorPercentThreshold 错误百分比达到多少触发熔断  "});index.add({'id':5,'href':'/docs/compose/ansible/tricks/','title':"tricks",'content':"tricks  ansible小技巧\n "});index.add({'id':6,'href':'/docs/compose/ansible/common-roles/','title':"common-roles",'content':"common-roles 1. databases系列  MySQL MongoDB  2. 消息队列  RocketMQ  "});index.add({'id':7,'href':'/docs/kubernetes/posts/coredns-in-production/','title':"在kubernetes生产环境coredns",'content':"在kubernetes生产环境coredns .:53 { errors log health reload kubernetes cluster.local. in-addr.arpa ip6.arpa { pods insecure upstream 10.40.0.53 10.40.0.54 fallthrough in-addr.arpa ip6.arpa } autopath @kubernetes prometheus :9153 forward . 10.40.0.53 10.40.0.54 cache 30 } "});index.add({'id':8,'href':'/docs/kubernetes/posts/run-microk8s-on-ubuntu/','title':"在ubuntu上运行microk8s",'content':"在ubuntu上运行microk8s 不可抗拒的理由 Reliable, fast, small, upstream.\n  Fast install Get a full Kubernetes system running in under 60 seconds.\n  Secure Runs safely on your laptop with state of the art isolation.\n  Upstream CNCF binaries delivered to your laptop, with updates and upgrades.\n  Complete Includes a docker registry so you can make containers, push them, and deploy them all on your laptop.\n  Featureful Cool things you probably want to try on a small, standard K8s are all built-in. Just enable them and go.\n  Updates Get the daily build if you want it, or betas and milestones, or just stable point releases.\n  Upgrades When a new major version comes out, upgrade with a single command (or automatically).\n  GPGPU Passthrough Give MicroK8s a GPGPU and your docker containers can get all nice and CUDA.\n  Small Use MicroK8s in your CI/CD pipelines and get on with your day without headaches.\n  初始化步骤 snap安装，目前没有国内源，最好自带翻墙哟~  # 安装 sudo snap install microk8s --classic --channel=1.18/stable # 等待ready sudo microk8s status --wait-ready # 开启组件 sudo microk8s enable dns dashboard registry dashboard microk8s kubectl port-forward -n kube-system service/kubernetes-dashboard 10443:443 --address 0.0.0.0 "});index.add({'id':9,'href':'/docs/linux/','title':"linux",'content':"linux板块  工作数年了，回首整理一些知识\n 夯实基础，不忘初心\n主线：工作中的故事\n 以场景故事穿插知识学习  安排场景  大一新生刚刚接触计算机基础课程 攒钱终于组装了自己的第一台电脑 初级开发第一次使用linux系统 服务器被黑，使用iptables精确控制流量 想看墙外的世界，配置自己的翻墙工具 打造无缝翻墙环境，配置软路由 服务器越来越多，空闲时间越来越少，批量配置管理工具帮你忙 账户认证权限配置手忙脚乱，ldap帮你统一管理 生产故障起，开会复盘忙，终是监控漏，运维背锅侠，监控做得好，孩子老婆热炕头  "});index.add({'id':10,'href':'/docs/compose/ansible/','title':"ansible",'content':"ansible "});index.add({'id':11,'href':'/docs/n9e/','title':"n9e",'content':"n9e板块  基于open-falcon开发，融入了滴滴的最佳实践，由于改动太大，优化太多，产品上已经无法与Open-Falcon平滑兼容，故而单开一个项目\n  夜莺可以说是一个颠覆级版本，性能、易用性、可用性都做了大幅改进，在滴滴抗住了7.7亿（包括物理机、虚机、容器、网络、业务模块的）监控指标\n 意思就是open-falcon别用了，也不会再维护了，也不强制你更换，但是更好的夜莺已经来了，用不用你自己看着办。\n项目信息  git: https://github.com/didi/nightingale docs: https://n9e.didiyun.com/docs/  名词解释 树 n9e有一棵贯穿全局的大树，它承载了该公司的所有待监控资产（对象），姑且称它为\u0026quot;服务树\u0026rdquo;，树层级本身没有具体意义，当有人用了，自然就有了应有的含义，本质上，树是对资产的一个分组机制（规则/策略）。\n虽说灵活本没错，但是俺觉得，为了方便企业内部管理，必要的约束/规范还是需要的，尤其是大范围推广该系统的时候。可以加一个L2-L级别的节点的检测，也可以增加节点类型\n对象/资源/endpoint endpoint === 受管资源/对象\n endpoint的上报实体必定是一个机器(带IP) endpoint  资源组 白话：一组资源\nn9e：某个叶子节点下的所有endpoints\n"});index.add({'id':12,'href':'/docs/compose/','title':"编排",'content':"n9e板块  基于open-falcon开发，融入了滴滴的最佳实践，由于改动太大，优化太多，产品上已经无法与Open-Falcon平滑兼容，故而单开一个项目\n  夜莺可以说是一个颠覆级版本，性能、易用性、可用性都做了大幅改进，在滴滴抗住了7.7亿（包括物理机、虚机、容器、网络、业务模块的）监控指标\n 意思就是open-falcon别用了，也不会再维护了，也不强制你更换，但是更好的夜莺已经来了，用不用你自己看着办。\n项目信息  git: https://github.com/didi/nightingale docs: https://n9e.didiyun.com/docs/  名词解释 树 n9e有一棵贯穿全局的大树，它承载了该公司的所有待监控资产（对象），姑且称它为\u0026quot;服务树\u0026rdquo;，树层级本身没有具体意义，当有人用了，自然就有了应有的含义，本质上，树是对资产的一个分组机制（规则/策略）。\n虽说灵活本没错，但是俺觉得，为了方便企业内部管理，必要的约束/规范还是需要的，尤其是大范围推广该系统的时候。可以加一个L2-L级别的节点的检测，也可以增加节点类型\n对象/资源/endpoint endpoint === 受管资源/对象\n endpoint的上报实体必定是一个机器(带IP) endpoint  资源组 白话：一组资源\nn9e：某个叶子节点下的所有endpoints\n"});index.add({'id':13,'href':'/docs/golang/','title':"golang",'content':""});index.add({'id':14,'href':'/docs/linux/basic/','title':"linux基础知识",'content':"linux基础知识  别看各种高级的应用五花八门，都离不开系统的基础，网络的基础，身边总看到一些人，平日里总是拿着这权威指南，那详解的，一段时间后，一讨论，还是屁都不会，更别说生产实践了。\n 咱就拿如今最火的k8s来举例，它可以说是检验你综合能力的大考，linux基础，文件系统，shell，docker，负载均衡，dns，网络等，都需要掌握，独立部署和维护k8s集群缺一不可。\nkubernetes组件运行\n systemd syslog 基本网络常识 docker cgroup tls/ssl证书 etcd  kube-proxy\n iptables ipvs  Pod网络/CNI/NetworkPolicy\n 路由 ipip封装网络 iptables eBPF  Ingress\n nginx/traefik  随随便便罗列一些，k8s依赖应用，应用依赖基本知识，一旦能够做到庖丁解牛的程度，学什么都好轻松。\n应用方面的学习，基本是一通百通，同类产品熟练掌握一种即可，其他的类比差异化学习即可。\n 不出问题时，最好的文档时官方文档 出问题时，最快的文档是stackoverflow 最有效的文档是代码\n 入门最寂寞的方式就是看文档，其次是看书 最高效的方式是拜高手，讲的都是精髓，是精华\n 最讨厌的是自以为是，不懂装懂的人，此类人直接弃疗 如果你有东西值得我用知识与你交换，那么你也许能获得短暂的认可 必要的崇拜是有必要的，保持敬畏，往往会收获惊喜\n最喜欢的是那种惺惺相惜的感觉，互相肯定，共同进步\n技术不行，那就学做人；做人不行，那就深耕技术；啥也不行，那再见了您嘞\n"});index.add({'id':15,'href':'/docs/n9e/code/','title':"n9e源码学golang",'content':"n9e源码学golang TODO  通用概念  identity address   index分析  endpoint注册   tree管理 内部gin http server  中间件 验证   内部rpc 公共包之pool collector分析  各个方面指标获取方式以及意义 补充更多指标   metricValue格式 transfer分析 judge分析 hbs分析 index分析 alert分析 图表相关 报警媒介(短信/微信/电话/IM) tsdb分析  tsdb尝试编写adapter至其他时序DB   关于权限扩展  基于casbin进行权限扩展    改进点  DB关闭问题，小书写错误 部分单词拼写问题，小书写错误 报警详情页面图表自动刷新功能 图表无值时，时间轴会被展开（去除没值部分） 管理团队的时候，管理员和普通成员添加逻辑优化  "});index.add({'id':16,'href':'/docs/compose/terraform/','title':"terraform",'content':"terraform工具 "});index.add({'id':17,'href':'/docs/linux/monitor/','title':"监控",'content':"n9e源码学监控 "});index.add({'id':18,'href':'/docs/linux/interview/','title':"伪装者",'content':"面试 "});index.add({'id':19,'href':'/docs/linux/bigdata/','title':"大数据",'content':"大数据 "});index.add({'id':20,'href':'/docs/linux/bigdata/kafka/','title':"kafka管理员手册",'content':" 持久化消息队列\n "});index.add({'id':21,'href':'/docs/linux/bigdata/ogg/','title':"ogg",'content':"ogg ogg全名Oracle GoldenGate，是Oracle公司用于同步数据库的工具。\n1. 需求 监听源数据库MySQL/Oracle，将DML事件发送到Kafka中。\n2. 方案 2.1. 使用ogg（推荐） ogg支持MySQL和Oracle，将DML同步到kafka中，提供给后端使用。\n2.2. 使用canal canal是阿里开源的数据库同步/迁移工具，目前仅支持MySQL作为源数据库；对于Oracle，可以使用yugong同步到MySQL中，然后再基于canal进行binlog解析，最后同步到kafka中。\n3. ogg的安装部署（MySQL） 3.1. 准备材料  下载ogg二进制包  Oracle GoldenGate for Big Data 19.1.0.0.1 on Linux x86-64 Oracle GoldenGate 19.1.0.0.3 for MySQL on Linux x86-64   centos7  ogg-mysql(10.41.253.211) ogg-target(10.41.253.212)   JDK 1.8  /usr/local/jdk    3.2. 安装测试MySQL ubuntu\n# 安装 $ apt install mysql-server-5.7 -y # 简单配置 $ mysql_secure_installation # 添加binlog配置 $ grep -E \u0026#34;^(server-id|log_bin|binlog_format)\u0026#34; /etc/mysql/mysql.conf.d/mysqld.cnf server-id\t= 1 log_bin\t= /var/log/mysql/mysql-bin.log binlog_format\t=\trow $ mkdir /var/log/mysql \u0026amp;\u0026amp; \\  chown mysql:mysql -R /var/log/mysql $ systemctl restart mysqld centos7\n# 配置源 $ cd /tmp \u0026amp;\u0026amp; wget https://dev.mysql.com/get/mysql57-community-release-el7-9.noarch.rpm \u0026amp;\u0026amp; \\  rpm -i mysql57-community-release-el7-9.noarch.rpm # 安装mysql $ yum install mysql-server -y # 启动mysql $ systemctl start mysqld # 获取root密码 $ grep \u0026#39;temporary password\u0026#39; /var/log/mysqld.log # 初始化配置 $ mysql_secure_installation 建立测试库表\nCREATE DATABASE data CHARSET utf8; CREATE TABLE `data`.`t1` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(60) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; # ogg create user \u0026#39;ogg\u0026#39;@\u0026#39;%\u0026#39; identified by \u0026#39;Ogg.123456\u0026#39;; grant select on data.* to \u0026#39;ogg\u0026#39;@\u0026#39;%\u0026#39;; # mng create user \u0026#39;root\u0026#39;@\u0026#39;%\u0026#39; identified by \u0026#39;Ogg.123456\u0026#39;; grant all privileges on *.* to \u0026#39;ogg\u0026#39;@\u0026#39;%\u0026#39;; flush privileges; 3.3. 安装zookeeper以及kafka bin/zookeeper-server-start.sh -daemon config/zookeeper.properties bin/kafka-server-start.sh -daemon config/server.properties 3.4. 安装ogg # base /opt/ogg # /etc/profile export OGG_HOME=/opt/ogg export PATH=$OGG_HOME:$PATH export LD_LIBRARY_PATH=$OGG_HOME:$JAVA_HOME/jre/lib/amd64/server:$LD_LIBRARY_PATH 3.5. 配置ogg-mysql 3.5.1. 初始化目录 oggsci\u0026gt; create subdirs 3.5.2. 配置启动mgr进程 oggsci\u0026gt; edit param mgr port 7809 dynamicportlist 7840-7939 autorestart er *, retries 5, waitminutes 3 purgeoldextracts /opt/ogg/dirdat/*,usecheckpoints, minkeepdays 7 oggsci\u0026gt; start mgr oggsci\u0026gt; info mgr  port: 进程的默认监听端口 dynamicportlist：动态端口列表 autorestart：重启参数，配置重启所有extract进程 purgeoldextracts：TRAIL文件的定期清理策略  3.5.3. 配置启动extract进程 oggsci\u0026gt; edit param extmysql extract extmysql sourcedb data@ogg-mysql:3306 userid ogg password Ogg.123456 exttrail /opt/ogg/dirdat/om TranLogOptions AltLogDest /var/log/mysql/mysql-bin.index table data.t1; # 添加extract oggsci\u0026gt; add extract extmysql,tranlog,begin now # 绑定extract和trail oggsci\u0026gt; add exttrail /opt/ogg/dirdat/om,extract extmysql 3.5.4. 配置传输pump进程 oggsci\u0026gt; edit param pumpcp extract pumpcp passthru sourcedb data@ogg-mysql:3306 userid ogg password Ogg.123456 rmthost ogg-target,mgrport 7809,compress rmttrail /opt/ogg/dirdat/om dynamicresolution numfiles 3000 table data.t1; # 分别添加本地trail文件和目标端trail文件绑定到mcp1进程 oggsci\u0026gt; add extract pumpcp,exttrailsource /opt/ogg/dirdat/om oggsci\u0026gt; add rmttrail /opt/ogg/dirdat/om,extract pumpcp 3.5.5. 创建定义文件 ggsci\u0026gt; edit param defgen defsfile ./dirdef/datat1.def sourcedb data@ogg-mysql:3306 userid ogg password Ogg.123456 table data.t1; $ defgen paramfile ./dirprm/defgen.prm $ scp ./dirdef/datat1.def ogg-target:/ogg/dirdef/ 3.6. 配置ogg-target 3.6.1. 初始化目录 oggsci\u0026gt; create subdirs 3.6.2. 配置启动mgr进程 oggsci\u0026gt; edit param mgr port 7809 dynamicportlist 7840-7939 autorestart er *, retries 5, waitminutes 3 purgeoldextracts /opt/ogg/dirdat/*,usecheckpoints, minkeepdays 7 oggsci\u0026gt; start mgr oggsci\u0026gt; info mgr 3.6.3. 配置replicat进程 oggsci\u0026gt; edit param repkfk REPLICAT repkfk sourcedefs /opt/ogg/dirdef/datat1.def TARGETDB LIBFILE libggjava.so SET property=dirprm/kafka.props REPORTCOUNT EVERY 1 MINUTES, RATE GROUPTRANSOPS 10000 MAP data.t1, TARGET data.t1; oggsci\u0026gt; add replicat repkfk exttrail /opt/ogg/dirdat/om,checkpointtable ogg-mapping-tmpl.checkpoint kafka.props\ngg.handlerlist=kafkahandler gg.handler.kafkahandler.type=kafka gg.handler.kafkahandler.KafkaProducerConfigFile=custom_kafka_producer.properties gg.handler.kafkahandler.topicMappingTemplate=${tableName} gg.handler.kafkahandler.keyMappingTemplate=${primaryKeys} gg.handler.kafkahandler.SchemaTopicName=ogg-schema gg.handler.kafkahandler.format=json gg.handler.kafkahandler.mode=op gg.classpath=/usr/local/kafka/libs/* custom_kafka_producer.properties\nbootstrap.servers=localhost:9092 acks=1 reconnect.backoff.ms=1000 value.serializer=org.apache.kafka.common.serialization.ByteArraySerializer key.serializer=org.apache.kafka.common.serialization.ByteArraySerializer batch.size=16384 linger.ms=200 3.7. 启动并测试  ogg-mysql -\u0026gt; start mgr ogg-mysql -\u0026gt; start extract ogg-target -\u0026gt; start mgr ogg-mysql -\u0026gt; start pump ogg-mysql -\u0026gt; start replicat  监听kafka队列\n$ kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic t1 --from-beginning {\u0026#34;table\u0026#34;:\u0026#34;data.t1\u0026#34;,\u0026#34;op_type\u0026#34;:\u0026#34;U\u0026#34;,\u0026#34;op_ts\u0026#34;:\u0026#34;2020-07-08 20:18:21.000390\u0026#34;,\u0026#34;current_ts\u0026#34;:\u0026#34;2020-07-08T20:18:27.673000\u0026#34;,\u0026#34;pos\u0026#34;:\u0026#34;00000000000000003260\u0026#34;,\u0026#34;before\u0026#34;:{},\u0026#34;after\u0026#34;:{\u0026#34;ID\u0026#34;:3,\u0026#34;NAME\u0026#34;:\u0026#34;luoshuai1\u0026#34;}} "});index.add({'id':22,'href':'/docs/linux/shell/','title':"shell",'content':"shell\n"});index.add({'id':23,'href':'/docs/about-me/','title':"关于我",'content':"About Me \u0026lt;图片\u0026gt;\n 你好，感谢您的到访，希望你能对小站的内容感兴趣，如果你想进一步了解我，请关注本页内容。\n 我是Troy\n 生于1992年 居住于北京 运维工程师｜SRE工程师 k8s linux golang  "});index.add({'id':24,'href':'/docs/','title':"Docs",'content':""});index.add({'id':25,'href':'/docs/linux/basic/start-stop-daemon/','title':"start-stop-daemon指北",'content':"start-stop-daemon指北  管理系统级别守护进程\n 案例  以coredns说明start-stop-daemon的使用方式\n 启动\nstart-stop-daemon --start --background -m --oknodo --pidfile /var/run/coredns.pid --exec /data/services/coredns/coredns -- -conf /data/services/coredns/Corefile 关闭\nstart-stop-daemon --stop --pidfile /var/run/coredns.pid -R TERM/20/KILL/5 "});index.add({'id':26,'href':'/docs/linux/basic/systemd/','title':"systemd指北",'content':"使用systemd管理应用程序  linux上管理进程的方式多种多样，有python系列的supervisord，nodejs系列的pm2，linux命令start-stop-daemon，也有较为传统的sysinit的service，还有systemd方式，各有优缺点，该文主要讲述一下systemd管理服务的方式\n 咋编写 查手册，查文档，弄清程序运行基本概念，需要啥参数搞啥参数即可\n以redis.service为例搞事 [Unit] Description=Advanced key-value store After=network.target Documentation=http://redis.io/documentation, man:redis-server(1) [Service] Type=forking ExecStart=/usr/bin/redis-server /etc/redis/redis.conf PIDFile=/run/redis/redis-server.pid TimeoutStopSec=0 Restart=always User=redis Group=redis RuntimeDirectory=redis RuntimeDirectoryMode=2755 UMask=007 PrivateTmp=yes LimitNOFILE=65535 PrivateDevices=yes ProtectHome=yes ReadOnlyDirectories=/ ReadWritePaths=-/var/lib/redis ReadWritePaths=-/var/log/redis ReadWritePaths=-/var/run/redis NoNewPrivileges=true CapabilityBoundingSet=CAP_SETGID CAP_SETUID CAP_SYS_RESOURCE MemoryDenyWriteExecute=true ProtectKernelModules=true ProtectKernelTunables=true ProtectControlGroups=true RestrictRealtime=true RestrictNamespaces=true RestrictAddressFamilies=AF_INET AF_INET6 AF_UNIX # redis-server can write to its own config file when in cluster mode so we # permit writing there by default. If you are not using this feature, it is # recommended that you replace the following lines with \u0026#34;ProtectSystem=full\u0026#34;. ProtectSystem=true ReadWriteDirectories=-/etc/redis [Install] WantedBy=multi-user.target Alias=redis.service service的基本架子\n[Unit] ... [Service] ... [Install] [Unit] 部分，是该服务单元的描述信息，其中After可以决定依赖关系，比如该服务依赖于网络。\n[Service]部分，是描述服务怎么运行的核心部分，对于简单的服务，使用以下配置就可以运行：\n[Service] ExecStart=xxxx 默认Type = simple\n而redis本身配置文件/etc/redis/redis.conf中有daemonize yes的配置，所以应用本身就可以以守护进程的方式运行，这里Type就需要设置为forking，当然你也可以选择让它在前台运行，然后设置Type = simple。\n其他的配置就根据不同的运行需求进行配置啦，比如pid文件，重启策略，运行用户，当前工作目录，文件描述符，进程数限制，启动前准备运动，停止命令，停止前准备运动等，那是相当丰富的。\n[Install]部分，是安装部分，WantedBy=multi-user.target，就是说明该服务所在target，multi-user.target就是命令行状态\nQ\u0026amp;A systemd服务配置文件中的type该如何选择？ 参考stackoverflow-1274901，大致意思如下：\n可以根据平时我们命令行运行服务的情形来决定到底使用哪一种类型\n 如果启动服务，并且服务一直在前台运行，直到ctrl-c才能够退出服务，那么想都不用想，使用Type = simple即可。 如果命令行返回，并且服务一直在后台运行（服务直接以守护进程的方式运行啦），那么Type = forking绝对没错。 如果只是一些job类型的服务，运行一次就退出，可能做了一些变更，但是服务本身并没有遗留任何进程，那么可以选择使用Type = oneshot，可以在ExecStart=中set来设置一些东西，然后在ExecStop=中unset来取消一些设置，我们同时可以利用RemainAfterExit=true配置，来追踪该服务的状态。  其他的类型，对于小运维管理来说不是太常用，比如Type=notify需要结合socket使用；Type=dbus需要结合D-BUS使用。\n"});index.add({'id':27,'href':'/posts/','title':"博客",'content':""});index.add({'id':28,'href':'/posts/how-to-generate-server-certs/','title':"如何使用cfssl生成证书",'content':"记录一下cfssl生成证书的方式\n安装cfssl curl -L https://github.com/cloudflare/cfssl/releases/download/v1.4.1/cfssl_1.4.1_linux_amd64 -o cfssl chmod +x cfssl curl -L https://github.com/cloudflare/cfssl/releases/download/v1.4.1/cfssljson_1.4.1_linux_amd64 -o cfssljson chmod +x cfssljson curl -L https://github.com/cloudflare/cfssl/releases/download/v1.4.1/cfssl-certinfo_1.4.1_linux_amd64 -o cfssl-certinfo chmod +x cfssl-certinfo 生成证书 # 全局配置 cfssl print-defaults config \u0026gt; config.json cfssl print-defaults csr \u0026gt; csr.json cat \u0026gt; olab-server-csr.json \u0026lt;-EOF { \u0026#34;CN\u0026#34;: \u0026#34;kubernetes\u0026#34;, \u0026#34;hosts\u0026#34;: [ \u0026#34;127.0.0.1\u0026#34;, \u0026#34;localhost\u0026#34;, \u0026#34;192.168.199.1\u0026#34;, \u0026#34;172.17.6.252\u0026#34;, \u0026#34;kubernetes\u0026#34;, \u0026#34;kubernetes.default\u0026#34;, \u0026#34;kubernetes.default.svc\u0026#34;, \u0026#34;kubernetes.default.svc.cluster\u0026#34;, \u0026#34;kubernetes.default.svc.cluster.local\u0026#34;, \u0026#34;*.olab\u0026#34;, \u0026#34;kubernetes-dashboard\u0026#34; ], \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 }, \u0026#34;names\u0026#34;: [{ \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;ST\u0026#34;: \u0026#34;BJ\u0026#34;, \u0026#34;L\u0026#34;: \u0026#34;BJ\u0026#34;, \u0026#34;O\u0026#34;: \u0026#34;DEVOPS\u0026#34;, \u0026#34;OU\u0026#34;: \u0026#34;OLAB\u0026#34; }] } EOF cfssl gencert -initca ca-csr.json | cfssljson -bare ca cfssl gencert -ca=ca.pem -ca-key=ca-key.pem --config=ca-config.json -profile=kubernetes olab-server-csr.json | cfssljson -bare olab-server # nginx ingress cert kubectl create secret tls nginx-cert --key olab-server-key.pem --cert olab-server.pem -n kube-system "});index.add({'id':29,'href':'/posts/running-man/','title':"后浪",'content':"弹幕 那些口口声声， 一代不如一代的人，应该看着你们； 像我一样，我看着你们，满怀羡慕。 人类积攒了几千年的财富， 所有的知识、见识、智慧和艺术， 像是专门为你们准备的礼物； 现代文明的成果被层层打开， 可以尽情地享用； 自由学习一门语言， 学习一门手艺， 欣赏一部电影， 去遥远的地方旅行。 很多人， 从小你们就在自由探索自己的兴趣； 很多人在童年就进入了不惑之年； 不惑于自己喜欢什么， 不喜欢什么。 人与人之间的壁垒被打破， 你们只凭相同的爱好， 就能结交千万个值得干杯的朋友， 你们拥有了， 我们曾经梦寐以求的权利——选择的权利 你所热爱的就是你的生活， 你们有幸遇见这样的时代； 但是时代更有幸， 遇见这样的你们。 我看着你们， 满怀敬意。 向你们的专业态度致敬， 你们正在把传统的变成现代的， 把经典的变成流行的； 把学术的变成大众的， 把民族变成世界的；   你们把自己的热爱 变成了一个和成千上万的人分享快乐的事业， 向你们的自信致敬。 弱小的人， 才习惯嘲讽和否定； 内心强大的人， 从不吝啬赞美和鼓励。 向你们的大气致敬， 小人同而不和， 君子美美与共，和而不同。 更年轻的身体， 更容得下多元的文化审美和价值观。 有一天我终于发现， 不只是我们在如何教你们生活， 你们也在启发我们， 怎样去更好的生活。 那些抱怨一代不如一代的人， 应该看看你们； 就像我一样，我看着你们满怀感激； 因为你们这个世界会更喜欢中国， 因为一个国家最好看的风景， 就是这个国家的年轻人。 因为你们， 这世上的小说、音乐、电影所表现的青春 就不再是忧伤迷茫， 而是善良、勇敢、无私、无所畏惧。 是心里有火， 眼里有光。 不用活成我们想象中的样子， 我们这一代人的想象力不足以想象你们的未来； 如果你们依然需要我们的祝福， 那么， 奔涌吧，后浪 我们在同一条奔涌的河流。   "});index.add({'id':30,'href':'/posts/how-to-use-hugo-and-github-pages/','title':"hugo和ghpages简明了解",'content':"记录一下hugo和ghpages\n步骤记录  备个域名，如果没有，那就用xxx.github.io也是极好的~ 准备个github的仓库，放你的静态文件 下载hugo，初始化，找个您喜欢的主题，简单配置一下 在content下sei个CNAME文件，放您的域名 执行几个命令，一生成，一上传，再做个CNAME记录  得嘞，您基本就看到自个人的博客了\n用到的命令 # init hugo site hugo add site troy.wang # download theme git submodule add https://github.com/alex-shpak/hugo-book themes/book # generate static files to public hugo # commit static files cd public \u0026amp;\u0026amp; \\  git add . \u0026amp;\u0026amp; \\  git commit -m \u0026#34;init public\u0026#34; \\  git remote add origin https://github.com/ermazi/troy.wang.git \u0026amp;\u0026amp; \\  git push -u origin master # check domain dns record correct. dig troy.wang +nostats +nocomments +nocmd hugo如果需要支持book这个主题，那么需要使用hugo-extended版本哟，不然里面部分语法没法支持哟!  git操作 子模块操作，参考:git-submodule文档\n# 添加子模块 git submodule add https://github.com/ermazi/troy.wang.git public # 如果子模块在父repo中曾经拥有过，那么久干掉它 git rm --cached public # 子模块的提交依旧可以独立操作 # 但是如果子模块有变更，那么父模块也需要更新哟 git submodule update 当在一个新的地方需要拉整个父仓库的时候\n$ git submodule init Submodule \u0026#39;public\u0026#39; (https://github.com/ermazi/troy.wang.git) registered for path \u0026#39;public\u0026#39; Submodule \u0026#39;themes/book\u0026#39; (https://github.com/alex-shpak/hugo-book) registered for path \u0026#39;themes/book\u0026#39; $ git submodule update Cloning into \u0026#39;/data/troy.wang.src/public\u0026#39;... Cloning into \u0026#39;/data/troy.wang.src/themes/book\u0026#39;... Submodule path \u0026#39;public\u0026#39;: checked out \u0026#39;0f2a9b67844755d9cf5eea66b4e6c1f8662a8155\u0026#39; Submodule path \u0026#39;themes/book\u0026#39;: checked out \u0026#39;5be250b0e2e703a25f0db6c5081f60ba57e4bee5\u0026#39; 如果某个模块更新了，你可以进模块git pull，当然也可以选择更加方便的方法:\n$ git submodule update --remote remote: Enumerating objects: 115, done. remote: Counting objects: 100% (115/115), done. remote: Compressing objects: 100% (14/14), done. remote: Total 62 (delta 34), reused 62 (delta 34), pack-reused 0 Unpacking objects: 100% (62/62), done. From https://github.com/ermazi/troy.wang 0f2a9b6..c292a5a master -\u0026gt; origin/master Submodule path 'public': checked out 'c292a5abf1c29ac7fecf13ca95c1a6384ae93f62' "});index.add({'id':31,'href':'/docs/n9e/code/n9e-arch/','title':"n9e整体结构",'content':"11\n"});index.add({'id':32,'href':'/docs/n9e/code/http-framework/','title':"n9e的http框架",'content':"n9e的http框架使用 Web流程  初始化http.Server 配置logging,recovery,session中间件 装载路由routers 启动http服务 关闭处理平滑关闭  web服务源码 // server object var srv = \u0026amp;http.Server{ ReadTimeout: 10 * time.Second, WriteTimeout: 10 * time.Second, MaxHeaderBytes: 1 \u0026lt;\u0026lt; 20, } // start server func Start() { // get global config \tc := config.Get() // init middlewares \tloggerMid := middleware.LoggerWithConfig(middleware.LoggerConfig{SkipPaths: skipPaths}) recoveryMid := middleware.Recovery() store := cookie.NewStore([]byte(c.HTTP.Secret)) sessionMid := sessions.Sessions(\u0026#34;falcon-ng\u0026#34;, store) // debug mode? \tif c.Logger.Level != \u0026#34;DEBUG\u0026#34; { gin.SetMode(gin.ReleaseMode) middleware.DisableConsoleColor() } // gin instance \u0026amp;\u0026amp; use middlewares \tr := gin.New() r.Use(loggerMid, recoveryMid, sessionMid) // init routers \troutes.Config(r) // use address toolkit to get monapi server\u0026#39;s listen address  srv.Addr = address.GetHTTPListen(\u0026#34;monapi\u0026#34;) // assign gin handler to server \tsrv.Handler = r // use go routine to start http server \tgo func() { log.Println(\u0026#34;starting http server, listening on:\u0026#34;, srv.Addr) if err := srv.ListenAndServe(); err != nil \u0026amp;\u0026amp; err != http.ErrServerClosed { log.Fatalf(\u0026#34;listening %s occur error: %s\\n\u0026#34;, srv.Addr, err) } }() } // graceful shutdown http server with timeout 5s func Shutdown() { ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second) defer cancel() if err := srv.Shutdown(ctx); err != nil { log.Fatalln(\u0026#34;cannot shutdown http server:\u0026#34;, err) } } // close all func ending() { // trap signals  c := make(chan os.Signal, 1) signal.Notify(c, syscall.SIGINT, syscall.SIGTERM, syscall.SIGQUIT) select { case \u0026lt;-c: fmt.Printf(\u0026#34;stop signal caught, stopping... pid=%d\\n\u0026#34;, os.Getpid()) } logger.Close() http.Shutdown() fmt.Println(\u0026#34;portal stopped successfully\u0026#34;) }    Web中间件 日志 该日志中间件原本是gin的默认日志中间件，n9e中单独拎出来是为了:\n 添加自己需要的字段，比如打印Body 使用全局的logger日志包打日志  gin的默认日志中间件，在输出媒介，只支持传入io.Writer，默认os.Stdout，而logger包没有实现io.Writer接口的对象，只能侵入中间件进行修改。\n日志中间件源码 type LogFormatter func(params LogFormatterParams) string type LoggerConfig struct { // Optional. Default value is gin.defaultLogFormatter \tFormatter LogFormatter // Output is a writer where logs are written. \t// Optional. Default value is gin.DefaultWriter. \tOutput io.Writer // SkipPaths is a url path array which logs are not written. \t// Optional. \tSkipPaths []string } // 默认日志格式，通过ANSI颜色控制 var defaultLogFormatter = func(param LogFormatterParams) string { var statusColor, methodColor, resetColor string if param.IsOutputColor() { // \tstatusColor = param.StatusCodeColor() methodColor = param.MethodColor() resetColor = param.ResetColor() } if param.Latency \u0026gt; time.Minute { // Truncate in a golang \u0026lt; 1.8 safe way \tparam.Latency = param.Latency - param.Latency%time.Second } return fmt.Sprintf(\u0026#34;[GIN] |%s %3d %s| %13v | %15s |%s %-7s %s %s\\n%s\u0026#34;, statusColor, param.StatusCode, resetColor, param.Latency, param.ClientIP, methodColor, param.Method, resetColor, param.Path, param.ErrorMessage, ) } func LoggerWithConfig(conf LoggerConfig) gin.HandlerFunc { // 配置日志格式化 \tformatter := conf.Formatter if formatter == nil { formatter = defaultLogFormatter } // 配置日志输出，默认标准输出 \tout := conf.Output if out == nil { out = os.Stdout } // 判断是否是term，决定是否显示颜色 \tisTerm := true if w, ok := out.(*os.File); !ok || os.Getenv(\u0026#34;TERM\u0026#34;) == \u0026#34;dumb\u0026#34; || (!isatty.IsTerminal(w.Fd()) \u0026amp;\u0026amp; !isatty.IsCygwinTerminal(w.Fd())) { isTerm = false } // 跳过特定uri \tnotlogged := conf.SkipPaths var skip map[string]struct{} if length := len(notlogged); length \u0026gt; 0 { skip = make(map[string]struct{}, length) for _, path := range notlogged { skip[path] = struct{}{} } } // 因为是实现中间件，所以必须返回handlerFunc \treturn func(c *gin.Context) { // 定时器开启 \tstart := time.Now() // 获取url \tpath := c.Request.URL.Path // 获取原始请求参数 \traw := c.Request.URL.RawQuery var ( rdr1 io.ReadCloser rdr2 io.ReadCloser ) // 获取body， \tif c.Request.Method != \u0026#34;GET\u0026#34; { // 读取body，得到buf \tbuf, _ := ioutil.ReadAll(c.Request.Body) // 将Buffer实例转换为io.ReadCloser实例 \t// rdr1没必要转换，下面用的时候，也只需要实现io.Reader就行了，甚至不需要转换，直接拿buf给下面用就好了 \trdr1 = ioutil.NopCloser(bytes.NewBuffer(buf)) // rdr2需要转换为io.ReaderCloser，赋值给Body \trdr2 = ioutil.NopCloser(bytes.NewBuffer(buf)) c.Request.Body = rdr2 } // Process request \tc.Next() // 将请求相关信息打印出来 \tif _, ok := skip[path]; !ok { param := LogFormatterParams{ Request: c.Request, isTerm: isTerm, Keys: c.Keys, } // 记录当钱时间戳 \tparam.TimeStamp = time.Now() // 计算延迟，并非响应延迟 \tparam.Latency = param.TimeStamp.Sub(start) param.ClientIP = c.ClientIP() param.Method = c.Request.Method param.StatusCode = c.Writer.Status() param.ErrorMessage = c.Errors.ByType(gin.ErrorTypePrivate).String() param.BodySize = c.Writer.Size() if raw != \u0026#34;\u0026#34; { path = path + \u0026#34;?\u0026#34; + raw } param.Path = path // fmt.Fprint(out, formatter(param)) \tlogger.Info(formatter(param)) if c.Request.Method != \u0026#34;GET\u0026#34; { logger.Info(readBody(rdr1)) } } } } func readBody(reader io.Reader) string { buf := new(bytes.Buffer) buf.ReadFrom(reader) s := buf.String() return s } // 如果是线上运行，那么就清除颜色 func DisableConsoleColor() { consoleColorMode = disableColor }    这一块就是gin的日志中间件:\n 根据http信息格式化日志 打印http调试信息  知识点:\n 中间件写法，传入context，返回handlerFunc，通过c.Next继续处理请求，然后中间件继续执行 日志处理写法 io操作，针对于流处理，比如Body，既要日志处理Body信息，又要不影响Body后续处理，需要对Body流进行拷贝，io.ReadAll读取为字节，再将字节转换为buffer，再将buffer转换为ioutil.NopCloser，使其能够被重新赋给Body。 golang对于颜色显示的处理，这里使用字节数组，当然直接使用转义字符/字符串会更加直观  异常恢复 recovery中间件，表面上是处理异常恢复，实际上是针对http异常状态的一个统一处理。\nrecovery中间件源码 // 入口，传入os.Stderr func Recovery() gin.HandlerFunc { return RecoveryWithWriter(gin.DefaultErrorWriter) } // func RecoveryWithWriter(out io.Writer) gin.HandlerFunc { var logger *log.Logger if out != nil { logger = log.New(out, \u0026#34;\\n\\n\\x1b[31m\u0026#34;, log.LstdFlags) } return func(c *gin.Context) { // 注册一个defer func，所有请求最终都会进入 \tdefer func() { if err := recover(); err != nil { // custom error，页面错误均返回状态码200，然后打印错误信息，没必要使用status code来暴露错误 \tif e, ok := err.(errors.PageError); ok { c.JSON(200, gin.H{\u0026#34;err\u0026#34;: e.Message}) c.Abort() return } // Check for a broken connection, as it is not really a \t// condition that warrants a panic stack trace. \t// 检测连接错误 \tvar brokenPipe bool if ne, ok := err.(*net.OpError); ok { if se, ok := ne.Err.(*os.SyscallError); ok { if strings.Contains(strings.ToLower(se.Error()), \u0026#34;broken pipe\u0026#34;) || strings.Contains(strings.ToLower(se.Error()), \u0026#34;connection reset by peer\u0026#34;) { brokenPipe = true } } } if logger != nil { stack := stack(3) httpRequest, _ := httputil.DumpRequest(c.Request, false) headers := strings.Split(string(httpRequest), \u0026#34;\\r\\n\u0026#34;) for idx, header := range headers { current := strings.Split(header, \u0026#34;:\u0026#34;) if current[0] == \u0026#34;Authorization\u0026#34; { headers[idx] = current[0] + \u0026#34;: *\u0026#34; } } if brokenPipe { logger.Printf(\u0026#34;%s\\n%s%s\u0026#34;, err, string(httpRequest), reset) } else if gin.IsDebugging() { logger.Printf(\u0026#34;[Recovery] %s panic recovered:\\n%s\\n%s\\n%s%s\u0026#34;, timeFormat(time.Now()), strings.Join(headers, \u0026#34;\\r\\n\u0026#34;), err, stack, reset) } else { logger.Printf(\u0026#34;[Recovery] %s panic recovered:\\n%s\\n%s%s\u0026#34;, timeFormat(time.Now()), err, stack, reset) } } // If the connection is dead, we can\u0026#39;t write a status to it. \tif brokenPipe { c.Error(err.(error)) // nolint: errcheck \tc.Abort() } else { c.AbortWithStatus(http.StatusInternalServerError) } } }() c.Next() } } func stack(skip int) []byte { buf := new(bytes.Buffer) // the returned data \t// As we loop, we open files and read them. These variables record the currently \t// loaded file. \tvar lines [][]byte var lastFile string for i := skip; ; i++ { // Skip the expected number of frames \tpc, file, line, ok := runtime.Caller(i) if !ok { break } // Print this much at least. If we can\u0026#39;t find the source, it won\u0026#39;t show. \tfmt.Fprintf(buf, \u0026#34;%s:%d (0x%x)\\n\u0026#34;, file, line, pc) if file != lastFile { data, err := ioutil.ReadFile(file) if err != nil { continue } lines = bytes.Split(data, []byte{\u0026#39;\\n\u0026#39;}) lastFile = file } fmt.Fprintf(buf, \u0026#34;\\t%s: %s\\n\u0026#34;, function(pc), source(lines, line)) } return buf.Bytes() }    在n9e中，controller中，使用了自定义错误PageError\ntype PageError struct { Message string } func (p PageError) Error() string { return p.Message } func (p PageError) String() string { return p.Message } func Bomb(format string, a ...interface{}) { panic(PageError{Message: fmt.Sprintf(format, a...)}) } func Dangerous(v interface{}) { if v == nil { return } switch t := v.(type) { case string: if t != \u0026#34;\u0026#34; { panic(PageError{Message: t}) } case error: panic(PageError{Message: t.Error()}) } } 然后针对于页面异常PageErrro，统一封装返回json\n如果是特定其他异常，比如BrokenPipe之类的，会做特殊处理，比如打印请求调试，打印调用栈\n会话 session会话，为了满足http无状态而产生的一个概念，主要用于存储用户区别信息，主要有两种方式：\n 使用redis/mysql这类的共享存储，存于服务端 使用Cookie存于浏览器端，但是必须加密，秘钥固定不变  这类就使用了cookie加密存储session的方式\nsession中间件源码 // 初始化 store := cookie.NewStore([]byte(c.HTTP.Secret)) sessionMid := sessions.Sessions(\u0026#34;falcon-ng\u0026#34;, store) gin.Use(sessionMid) // 写入信息 session := sessions.Default(c) session.Set(\u0026#34;username\u0026#34;, user) session.Save() // 获取信息 value := session.Get(\u0026#34;username\u0026#34;)    验证 对于需要登录访问的接口，提供了middleware.Logined()中间件；对于内部访问的接口，提供了middleware.CheckHeaderToken()中间件，只需要在响应的接口组Use即可\n内建token验证中间件源码 const internalToken = \u0026#34;monapi-builtin-token\u0026#34; // CheckHeaderToken check thirdparty x-srv-token func CheckHeaderToken() gin.HandlerFunc { return func(c *gin.Context) { token := c.GetHeader(\u0026#34;x-srv-token\u0026#34;) if token != internalToken { errors.Bomb(\u0026#34;token[%s] invalid\u0026#34;, token) } c.Next() } } v1 := r.Group(\u0026#34;/v1/portal\u0026#34;).Use(middleware.CheckHeaderToken()) { v1.POST(\u0026#34;/endpoint\u0026#34;, endpointImport) }    仅有一处使用到该内建token，在index组件中，将endpoint存到endpoint表中。\n这里为啥不使用model中的EndpointImport方法，而非要调用接口，费解，如果使用EndpointImport，这样endpoint表在哪里读写，一目了然\n路由处理 代理 据透露，代理仅用于调试\nfunc indexReq(c *gin.Context) { target, err := url.Parse(fmt.Sprintf(\u0026#34;http://127.0.0.1:%d\u0026#34;, address.GetHTTPPort(\u0026#34;index\u0026#34;))) errors.Dangerous(err) proxy := httputil.NewSingleHostReverseProxy(target) c.Request.Header.Set(\u0026#34;X-Forwarded-Host\u0026#34;, c.Request.Header.Get(\u0026#34;Host\u0026#34;)) proxy.ServeHTTP(c.Writer, c.Request) } 接口设计 尽可能满足RESTful接口设计\nn9e接口源码 func Config(r *gin.Engine) { // 静态页面 \tr.Static(\u0026#34;/pub\u0026#34;, \u0026#34;./pub\u0026#34;) // 图标 \tr.StaticFile(\u0026#34;/favicon.ico\u0026#34;, \u0026#34;./pub/favicon.ico\u0026#34;) // 心跳检测 \thbs := r.Group(\u0026#34;/api/hbs\u0026#34;) { hbs.POST(\u0026#34;/heartbeat\u0026#34;, heartBeat) // 获取具体模块的所有实例，只包括judge和index \thbs.GET(\u0026#34;/instances\u0026#34;, instanceGets) } // portal接口 \tnolog := r.Group(\u0026#34;/api/portal\u0026#34;) { // 健康接口 \tnolog.GET(\u0026#34;/ping\u0026#34;, ping) // 版本 \tnolog.GET(\u0026#34;/version\u0026#34;, version) // pid \tnolog.GET(\u0026#34;/pid\u0026#34;, pid) // remote addr \tnolog.GET(\u0026#34;/addr\u0026#34;, addr) // 登录接口 \tnolog.POST(\u0026#34;/auth/login\u0026#34;, login) // 退出登录 \tnolog.GET(\u0026#34;/auth/logout\u0026#34;, logout) // 获取邀请token \tnolog.GET(\u0026#34;/users/invite\u0026#34;, userInviteGet) // 邀请用户注册 \tnolog.POST(\u0026#34;/users/invite\u0026#34;, userInvitePost) // 获取endpoint的所有采集配置项 \tnolog.GET(\u0026#34;/collects/:endpoint\u0026#34;, collectGetByEndpoint) // 获取策略 \tnolog.GET(\u0026#34;/stras/effective\u0026#34;, effectiveStrasGet) nolog.GET(\u0026#34;/stras\u0026#34;, strasAll) } login := r.Group(\u0026#34;/api/portal\u0026#34;).Use(middleware.Logined()) { // profile获取 \tlogin.GET(\u0026#34;/self/profile\u0026#34;, selfProfileGet) login.PUT(\u0026#34;/self/profile\u0026#34;, selfProfilePut) login.PUT(\u0026#34;/self/password\u0026#34;, selfPasswordPut) // 用户列表 \tlogin.GET(\u0026#34;/user\u0026#34;, userListGet) // 添加用户 \tlogin.POST(\u0026#34;/user\u0026#34;, userAddPost) // 获取用户profile \tlogin.GET(\u0026#34;/user/:id/profile\u0026#34;, userProfileGet) // 修改profile \tlogin.PUT(\u0026#34;/user/:id/profile\u0026#34;, userProfilePut) // 修改密码 \tlogin.PUT(\u0026#34;/user/:id/password\u0026#34;, userPasswordPut) // 删除用户 \tlogin.DELETE(\u0026#34;/user/:id\u0026#34;, userDel) // 获取team \tlogin.GET(\u0026#34;/team\u0026#34;, teamListGet) // 添加team \tlogin.POST(\u0026#34;/team\u0026#34;, teamAddPost) // 更新team \tlogin.PUT(\u0026#34;/team/:id\u0026#34;, teamPut) // 删除team \tlogin.DELETE(\u0026#34;/team/:id\u0026#34;, teamDel) // 获取endpoints \tlogin.GET(\u0026#34;/endpoint\u0026#34;, endpointGets) // 导入endpoints \tlogin.POST(\u0026#34;/endpoint\u0026#34;, endpointImport) // 修改endpoint，主要是改alias \tlogin.PUT(\u0026#34;/endpoint/:id\u0026#34;, endpointPut) // 删除endpoint \tlogin.DELETE(\u0026#34;/endpoint\u0026#34;, endpointDel) // 根据idents获取对应绑定的节点 \tlogin.GET(\u0026#34;/endpoints/bindings\u0026#34;, endpointBindingsGet) // 根据节点id获取endpoints \tlogin.GET(\u0026#34;/endpoints/bynodeids\u0026#34;, endpointByNodeIdsGets) // 获取tree信息 \tlogin.GET(\u0026#34;/tree\u0026#34;, treeGet) // 搜索tree获取节点 \tlogin.GET(\u0026#34;/tree/search\u0026#34;, treeSearchGet) // 添加节点 \tlogin.POST(\u0026#34;/node\u0026#34;, nodePost) // 修改节点名字 \tlogin.PUT(\u0026#34;/node/:id/name\u0026#34;, nodeNamePut) // 删除节点 \tlogin.DELETE(\u0026#34;/node/:id\u0026#34;, nodeDel) // 获取node节点下的所有endpoints \tlogin.GET(\u0026#34;/node/:id/endpoint\u0026#34;, endpointsUnder) // 绑定节点和endpoint \tlogin.POST(\u0026#34;/node/:id/endpoint-bind\u0026#34;, endpointBind) // 解绑节点和endpoint \tlogin.POST(\u0026#34;/node/:id/endpoint-unbind\u0026#34;, endpointUnbind) // 获取屏蔽配置 \tlogin.GET(\u0026#34;/node/:id/maskconf\u0026#34;, maskconfGets) // 获取screen \tlogin.GET(\u0026#34;/node/:id/screen\u0026#34;, screenGets) // 添加screen \tlogin.POST(\u0026#34;/node/:id/screen\u0026#34;, screenPost) // 节点搜索 \tlogin.GET(\u0026#34;/nodes/search\u0026#34;, nodeSearchGet) // 获取节点叶子节点 \tlogin.GET(\u0026#34;/nodes/leafids\u0026#34;, nodeLeafIdsGet) // 获取节点的所有父节点 \tlogin.GET(\u0026#34;/nodes/pids\u0026#34;, nodePidsGet) // 获取所有节点 \tlogin.GET(\u0026#34;/nodes/byids\u0026#34;, nodesByIdsGets) // 添加屏蔽 \tlogin.POST(\u0026#34;/maskconf\u0026#34;, maskconfPost) // 修改屏蔽 \tlogin.PUT(\u0026#34;/maskconf/:id\u0026#34;, maskconfPut) // 删除屏蔽 \tlogin.DELETE(\u0026#34;/maskconf/:id\u0026#34;, maskconfDel) // 修改screen \tlogin.PUT(\u0026#34;/screen/:id\u0026#34;, screenPut) // 删除screen \tlogin.DELETE(\u0026#34;/screen/:id\u0026#34;, screenDel) // 获取某screen下的所有subclass \tlogin.GET(\u0026#34;/screen/:id/subclass\u0026#34;, screenSubclassGets) // 添加某screen下的subclass \tlogin.POST(\u0026#34;/screen/:id/subclass\u0026#34;, screenSubclassPost) // 修改subclass \tlogin.PUT(\u0026#34;/subclass\u0026#34;, screenSubclassPut) // 删除subclass \tlogin.DELETE(\u0026#34;/subclass/:id\u0026#34;, screenSubclassDel) // 获取某subclass下的所有chart \tlogin.GET(\u0026#34;/subclass/:id/chart\u0026#34;, chartGets) // 在某subclass下添加chart \tlogin.POST(\u0026#34;/subclass/:id/chart\u0026#34;, chartPost) // 修改subclass的screen \tlogin.PUT(\u0026#34;/subclasses/loc\u0026#34;, screenSubclassLocPut) // 修改chart \tlogin.PUT(\u0026#34;/chart/:id\u0026#34;, chartPut) // 删除chart \tlogin.DELETE(\u0026#34;/chart/:id\u0026#34;, chartDel) // 修改charts的权重，该权重用于排序 \tlogin.PUT(\u0026#34;/charts/weights\u0026#34;, chartWeightsPut) // 图表调试用 \tlogin.GET(\u0026#34;/tmpchart\u0026#34;, tmpChartGet) login.POST(\u0026#34;/tmpchart\u0026#34;, tmpChartPost) // 报警==事件 \t// 事件获取 \tlogin.GET(\u0026#34;/event/cur\u0026#34;, eventCurGets) // 根据id获取事件 \tlogin.GET(\u0026#34;/event/cur/:id\u0026#34;, eventCurGetById) // 删除事件 \tlogin.DELETE(\u0026#34;/event/cur/:id\u0026#34;, eventCurDel) // 获取事件历史 \tlogin.GET(\u0026#34;/event/his\u0026#34;, eventHisGets) // 根据id获取事件历史 \tlogin.GET(\u0026#34;/event/his/:id\u0026#34;, eventHisGetById) // 添加认领人 \tlogin.POST(\u0026#34;/event/curs/claim\u0026#34;, eventCurClaim) // 添加采集信息 \tlogin.POST(\u0026#34;/collect\u0026#34;, collectPost) // 获取采集信息列表 \tlogin.GET(\u0026#34;/collect/list\u0026#34;, collectsGet) // 获取采集信息列表 \tlogin.GET(\u0026#34;/collect\u0026#34;, collectGet) // 修改采集项 \tlogin.PUT(\u0026#34;/collect\u0026#34;, collectPut) // 删除采集项 \tlogin.DELETE(\u0026#34;/collect\u0026#34;, collectsDel) // 采集项正则检测 \tlogin.POST(\u0026#34;/collect/check\u0026#34;, regExpCheck) // 添加策略 \tlogin.POST(\u0026#34;/stra\u0026#34;, straPost) // 修改策略 \tlogin.PUT(\u0026#34;/stra\u0026#34;, straPut) // 删除策略 \tlogin.DELETE(\u0026#34;/stra\u0026#34;, strasDel) // 获取策略 \tlogin.GET(\u0026#34;/stra\u0026#34;, strasGet) // 获取某个策略 \tlogin.GET(\u0026#34;/stra/:sid\u0026#34;, straGet) } v1 := r.Group(\u0026#34;/v1/portal\u0026#34;).Use(middleware.CheckHeaderToken()) {\t// 导入endpoint \tv1.POST(\u0026#34;/endpoint\u0026#34;, endpointImport) } // 本地调试用 \ttransferProxy := r.Group(\u0026#34;/api/transfer\u0026#34;) { transferProxy.GET(\u0026#34;/req\u0026#34;, transferReq) transferProxy.POST(\u0026#34;/data\u0026#34;, transferReq) transferProxy.POST(\u0026#34;/data/ui\u0026#34;, transferReq) transferProxy.POST(\u0026#34;/push\u0026#34;, transferReq) } // 本地调试用 \tindexProxy := r.Group(\u0026#34;/api/index\u0026#34;) { indexProxy.POST(\u0026#34;/metrics\u0026#34;, indexReq) indexProxy.POST(\u0026#34;/tagkv\u0026#34;, indexReq) indexProxy.POST(\u0026#34;/counter/fullmatch\u0026#34;, indexReq) indexProxy.POST(\u0026#34;/counter/clude\u0026#34;, indexReq) indexProxy.POST(\u0026#34;/counter/detail\u0026#34;, indexReq) } }    各类资源通用模式/模板  添加资源 POST /api/portal/res 获取列表 GET /api/portal/res 获取某个资源 GET /api/portal/res/:id 更新某个资源 PUT /api/portal/res/:id 更新某个资源的某一项 PUT /api/portal/res/:id/item 获取子资源 GET /api/portal/res/:id/subres/:subid 添加子资源 POST /api/portal/res/:id/subres/:subid 修改子资源 PUT /api/portal/subres/:subid 删除子资源 DELETE /api/portal/subres/:subid  附录 信号相关 SIGINT,SIGTERM,SIGQUIT和SIGHUP默认行为都是杀掉进程，但是用户可以拦截他们，并这些信号添加自己的处理逻辑，所以不同的应用需要小心嘞，它可能不是系统默认行为。\nSIGKILL-9 必杀技！从不失败（但是针对一些进程状态异常的，可能有问题），这个信号很危险，不会给进程反应的时间，会导致一些资源没法清理，比如缓存目录，正在处理的连接等SIGINT-2 相当弱的一个信号，传统的意义是：停止正在做的，等待用户后续输入。在终端中通常由Ctrl+C产生；在非交互式的程序中，跟SIGTERM类似，就是杀死进程。SIGTERM-15 这是最正常的杀进程信号，它通知应用进程干净地死去，应用进程可能会处理一些后事，比如保存状态，释放资源等；但是特别重要的进程也会选择忽略SIGTERM信号。SIGHUP-1 SIGHUP is about the same as SIGTERM in terms of harshness, but it has a specific role because it\u0026rsquo;s automatically sent to applications running in a terminal when the user disconnects from that terminal (etymologically, because the user was connecting via a telephone line and the modem hung up). SIGHUP is often involuntary, unlike SIGTERM which has to be sent explicitly, so applications should try to save their state on a SIGHUP. SIGHUP also has a completely different conventional meaning for non-user-facing applications (daemons), which is to reload their configuration file.SIGQUIT-3 SIGQUIT is the harshest of the ignorable signals. It\u0026rsquo;s meant to be used when an application is misbehaving and needs to be killed now, and by default it traditionally left a core dump file (modern systems where most users wouldn\u0026rsquo;t know what a core file is tend to not produce them by default). Applications can set a handler but should do very little (in particular not save any state) because the intent of SIGQUIT is to be used when something is seriously wrong. 颜色相关 参考: ANSI转义序列\n在bash中使用颜色:\necho -e \u0026#34;\\033[32m绿色字\\033[0m\u0026#34; \\033是八进制表示2，或者十六进制\\x1b表示，或者字节数组29表示，在ASCII中代表ESC，是不可打印的字符\nANSI控制序列三部分构成: 前置引导，CSI控制序列，结束符号。\nCSI控制序列主要是控制输出样式的，比如颜色， 光标等\u0026hellip; ，格式为:[\u0026lt;PREFIX\u0026gt;];[\u0026lt;COLOR\u0026gt;];[\u0026lt;TEXT DECORATION\u0026gt;]，其中：\n PREFIX： 使用的 256的颜色模式，后面将介绍。 COLOR： 输出颜色，前景色等 TEXT DECORATION: 文字装饰器，比如下划线等(1粗2深3下划线4斜体42背景绿)  n9e中用字节表示:\n/* 27 -\u0026gt; \\33 91 -\u0026gt; [ 57 -\u0026gt; 9 55 -\u0026gt; 7 59 -\u0026gt; ; 52 -\u0026gt; 4 50 -\u0026gt; 2 109 -\u0026gt; m */ // 代表绿底白字 []byte{27, 91, 57, 55, 59, 52, 50, 109} "});index.add({'id':33,'href':'/docs/linux/monitor/collector-metrics/','title':"n9e默认监控指标",'content':"分析collector组件的源码，查看一下n9e默认采集的一些指标，并尽可能理解含义。\n系统指标 CPU    metric 说明 必要性 采集来源     cpu.idle 空闲     cpu.util 使用率     cpu.user 用户使用率     cpu.sys 系统使用率     cpu.nice 低优先级使用率     cpu.iowait iowait使用率 并不一定反应io繁忙程度    cpu.irq 中断请求     cpu.softirq 软中断请求     cpu.steal      cpu.guest      cpu.switches 上下文切换     cpu.core.* 各个核心的指标      磁盘    metric 说明 必要性 采集来源     disk.bytes.total 某盘总空间  du   disk.bytes.free 剩余空间  du   disk.bytes.used 已使用  du   disk.bytes.used.percent 已使用百分比  du   disk.inodes.total      disk.inodes.free      disk.inodes.used      disk.inodes.used.percent      disk.cap.bytes.total 某实例总空间     disk.cap.bytes.used      disk.cap.bytes.free      disk.cap.bytes.used.percent      disk.io.read.request 每秒读请求数 读iops    disk.io.write.request 每秒写请求数 写iops    disk.io.read.bytes 读吞吐 读吞吐    disk.io.write.bytes 写吞吐 写吞吐    disk.io.avgrq_sz 平均每I/O操作数据大小  delta(rsect+wsect)/delta(rio+wio)   disk.io.avgqu_sz 平均I/O队列长度  delta(aveq)/s/1000   disk.io.await 平均每次设备I/O操作的等待时间 (毫秒) 队列+磁盘操作 delta(ruse+wuse)/delta(rio+wio)   disk.io.svctm 平均每次设备I/O操作的服务时间 (毫秒) 磁盘操作 delta(use)/delta(rio+wio)   disk.io.util      disk.rw.error 磁盘是否可读写  读写文件测试    内存    metric 说明 必要性 采集来源     mem.bytes.total 总内存     mem.bytes.used 总使用     mem.bytes.free 总剩余     mem.bytes.used.percent 使用率     mem.bytes.buffers 缓冲占用     mem.bytes.cached 缓存占用     mem.swap.bytes.total swap总     mem.swap.bytes.used swap使用     mem.swap.bytes.free swap剩余     mem.swap.bytes.used.percent swap使用率      网络    metric 说明 必要性 采集来源     net.in.bits 入站bps     net.out.bits 出站bps     net.in.dropped 入丢弃bps     net.out.dropped 出丢弃bps     net.in.pps 入包转发率     net.out.pps      net.in.errs 入错误率     net.out.errs 出错误率     net.in.percent 入带宽占比     net.out.percent 出带宽占比     net.bandwidth.mbits 网卡带宽/速率     net.bandwidth.mbits.total 网卡总带宽     net.in.bits.total 总入站     net.out.bits.total 总出站     net.in.bits.total.percent 总入使用率     net.out.bits.total.percent 总出使用率     sockets.used 已使用socks数量     sockets.tcp.inuse tcp使用的数量     sockets.tcp.timewait timewait的数量      系统    metric 说明 必要性 采集来源     cpu.loadavg.1 1分钟均载     cpu.loadavg.5 5分钟均载     cpu.loadavg.15 15分钟均载     sys.net.netfilter.nf_conntrack_max      sys.net.netfilter.nf_conntrack_count      sys.net.netfilter.nf_conntrack_count.percent      sys.ntp.offset.ms ntp偏移     sys.fs.files.max      sys.fs.files.free      sys.fs.files.used      sys.fs.files.used.percent      sys.ps.process.total      sys.ps.entity.total       进程    metric 说明 必要性 采集来源     proc.port.listen      proc.num       日志 其他 组件指标    metric 说明 必要性 采集来源     proc.agent.alive collector存活指标 collector是否存活 固定值          "});index.add({'id':34,'href':'/docs/compose/terraform/terraform/','title':"terraform",'content':"terraform 名词解释 Meta-Arguments cli可以在resource中使用meta-arguments，来改变资源的行为：\n depends_on 显式指定依赖 count 根据count指定多个资源，可以使用count.index引用当前count for_each 根据map或者set来创建多个资源，key用each.key，value用each.value provider 选择一个非默认的provider lifecycle 定义生命周期 provisioner and connection 资源创建成功以后做一些事，比如注册啊，执行配置管理任务啊之类的  https://alex.dzyoba.com/blog/terraform-ansible/    "});index.add({'id':35,'href':'/docs/compose/terraform/aliyun/','title':"terraform-aliyun",'content':"阿里云常用资源terraform栗子 slb resource alicloud_slb main { name = var.name specification = var.spec == \u0026quot;None\u0026quot; ? null : var.spec address_type = var.vswitchid == \u0026quot;\u0026quot; ? \u0026quot;internet\u0026quot; : \u0026quot;intranet\u0026quot; vswitch_id = var.vswitchid == \u0026quot;\u0026quot; ? null : var.vswitchid delete_protection = var.delete_protection instance_charge_type = \u0026quot;PostPaid\u0026quot; } "});index.add({'id':36,'href':'/docs/compose/terraform/data-type/','title':"terraform数据类型",'content':"terraform数据类型\n string number bool list tuple map object null  "});index.add({'id':37,'href':'/docs/compose/terraform/data-agg/','title':"terraform资料聚合",'content':"terraform资料聚合\n各种链接入口  所有providers  阿里云provider   所有backends 内建函数  文章  Terraform tips \u0026amp; tricks: loops, if-statements, and gotchas  "});index.add({'id':38,'href':'/docs/linux/interview/interview-s1/','title':"伪装者-S1",'content':"1.给定一个nginx的日志access.log，请输出实时的qps.\nwhile true do datatime=`date +%d/%b/%Y:%T` a=`grep \u0026#34;$datatime\u0026#34; /var/log/nginx/access.log|wc -l` echo \u0026#34;$a\u0026#34; sleep 1 done 2.现有一个100G大小的日志文件，由于时间因素，只允许读取一次，但需要分别将含有两个pattern的行输出到两个文件中，请给出方案\n假设pattern1和pattern2\nawk \u0026#39;{ if ($0 ~ /pattern1/ ) print $0 \u0026gt;\u0026gt; \u0026#34;a\u0026#34;; if ( $0 ~ /pattern2/ ) print $0 \u0026gt;\u0026gt; \u0026#34;b\u0026#34;}\u0026#39; sample.txt 3.发现某IP无法访问，请给出尽可能详细的诊断方案，定位可能存在的问题。（目标机器宕机、近机房端网络中断、骨干网问题、或者其他可能的问题。）\n ping目标机器 mtr/traceroute该IP，看到哪个节点有问题 网络路径上进行抓包tcpdump  4.uptime命令的输出中有load average: 0.24, 0.30, 0.24，请(1)解释这里load的数值的含义；(2)说明该数值多大时表示系统负载很高；(3)当系统负载高时，如何找出是什么因素导致负载高的。\n uptime三个值分别为1分钟，5分钟和15分钟的平均负载 当负载值大于等于CPU核心数的时候，表明负载很高 使用top或者类似的工具（dstat），查看cpu相关指标  5.现在有一个大小约1g的源代码目录（如linux内核源码），需要从机器A上传输到机器B上。请给出两到三种方案，并陈述各方案的优劣。\n由于是源码文件，那么小问题一定是非常多的，最好先打包压缩，然后再使用scp或者rsync进行传输。\n scp传输加密 rsync比较灵活，可以排除部分文件/目录 压缩完后再传输，利用计算资源节省网络带宽提升效率 也可以直接起一个python http server，然后对端下载  6.现有一个目录，其中有一百万(数量级)个的小文件，请给出两到三种删除该目录的方法，并陈述各方案的优劣。\n rm -rf /data/dst这个方法可以，慢慢等，千万不要rm -rf /data/dst/*，小文件会列出来，参数列表过长，报错 find /data/dst -type f | xargs rm -f该方法能删除，但是会比较慢 ``find /data/dst -type f -delete`该方法能删除，比2快 mkdir /tmp/dst \u0026amp;\u0026amp; rsync --delete-before -a -H -v --progress --stats /tmp/dst/ /data/dst利用rsync的--delete选项来删除  "});index.add({'id':39,'href':'/docs/n9e/code/regex/','title':"正则小剧场",'content':"正则小剧场 golang默认的正则，并非pcre正则，像正则断言的语法，golang就不支持\n这里提供一个正则测试网站: regex101\n零宽断言 零宽断言是匹配宽度为零，满足一定的条件/断言,通常用于查找在特定内容，该内容前或者后满足一定条件，但是匹配内容又不包括这些条件。\n零宽断言可以拆成两部分理解，零宽和断言。\n 零宽: 代表满足条件，但是不作为匹配内容，看上去好像宽度为零 断言: 声明一个应该为真的事实，只有当断言为真时才会继续进行匹配  断言条件所在的位置(前后)以及断言条件是否取反(正负)，又可以将零宽断言分为四种: 负向先行/负向后发/先行/后发。\n具体表达式:\n (?=表达式) (?!表达式) (?\u0026lt;表达式) (?\u0026lt;!表达式)  实践 提醒\nmacos系统的grep不支持-P选项，一下均使用linux中的grep测试，可以使用在线正则regex101网站进行测试  样本 $ cat \u0026gt; /tmp/text \u0026lt;\u0026lt;-EOF \u0026gt; api01retcode000000 \u0026gt; api01retcode000001 \u0026gt; api01retcode000002 \u0026gt; api02retcode000000 \u0026gt; api02retcode000001 \u0026gt; api02retcode000002 \u0026gt; api03retcode000000 \u0026gt; api03retcode000001 \u0026gt; api02retcode000002 \u0026gt; EOF 先行正断言 # 先行正断言 retcode(?=000000)(\\d{6}) $ grep -P \u0026#39;retcode(?=000000)(\\d{6})\u0026#39; /tmp/text api01retcode000000 api02retcode000000 api03retcode000000 先行负断言 # 先行负断言 retcode(?=000000)(\\d{6}) $ grep -P \u0026#39;retcode(?!000000)(\\d{6})\u0026#39; /tmp/text api01retcode000001 api01retcode000002 api02retcode000001 api02retcode000002 api03retcode000001 api02retcode000002 后发正断言 # 后发正断言 (?\u0026lt;=api01)retcode(\\d{6}) $ grep -P \u0026#39;(?\u0026lt;=api01)retcode(\\d{6})\u0026#39; /tmp/text api01retcode000000 api01retcode000001 api01retcode000002 后发负断言 # 后发负断言 (?\u0026lt;!api01)retcode(\\d{6}) $ grep -P \u0026#39;(?\u0026lt;!api01)retcode(\\d{6})\u0026#39; /tmp/text api02retcode000000 api02retcode000001 api02retcode000002 api03retcode000000 api03retcode000001 api02retcode000002 非捕获分组 另外还有个不进行断言，而是作为非捕获分组存在，比如需要使用小括号进行或操作，但是不想改内容作为分组匹配内容时，可以使用，语法为:(?:mo|fa)ther\n"});index.add({'id':40,'href':'/docs/linux/shell/abs/','title':"高级bash脚本编程",'content':"高级bash脚本编程 变量 内部变量   $BASH\n  $EDITOR\n  $EUID 有效用户ID\n  $FUNCNAME 当前函数名\n  $GLOBIGNORE 文件名模式匹配列表，忽略\n  $GROUPS 当前用户所属的组\n  $HOME\n  $HOSTNAME\n  $HOSTTYPE 当前主机类型\n  $IFS 内部域分隔符，默认为空白(空格, 制表符,和换行符)，这个变量用来决定Bash在解释字符串时如何识别域, 或者单词边界.\n  $ echo $IFS | cat -vte $   $ bash -c \u0026#39;set w x y z; IFS=\u0026#34;+\u0026#34;; echo \u0026#34;$*\u0026#34;\u0026#39; w+x+y+z     $LINENO 记录自身在脚本中的行号\n  $OLDPWD 之前所在目录\n  $PATH 可执行文件搜索路径\n  $PPID 父进程PID\n  $PS1 主提示符\n  $PS2 第二提示符，当需要额外输入的时候，就会看到它，默认为\u0026gt;\n  $PS3 select循环中显示\n  $PS4 当使用-x调试脚本的时候，每行开头显示的，默认为+\n  $PWD 当前路径\n  $TMOUT 超时\u0026rsquo;\n  #!/bin/bash TMOUT=3 # 提示输入时间为3秒. echo \u0026#34;What is your favorite song?\u0026#34; echo \u0026#34;Quickly now, you only have $TMOUTseconds to answer!\u0026#34; read song if [ -z \u0026#34;$song\u0026#34; ] then song=\u0026#34;(no answer)\u0026#34; fi echo \u0026#34;Your favorite song is $song.\u0026#34;     $UID\n  $0,$1,$2,\u0026hellip;,${10}\u0026hellip; 位置参数，从命令行传给脚本，或者使用set接收\n  $# 位置参数的个数\n  $* 所有的位置参数都被看成一个单词\n  $@ 所有位置参数，但是每个参数都是独立的引用字符串\n  $! 运行在后台的最后一个作业的PID\n  $_ 之前执行命令的最后一个参数\n  $? 命令函数脚本本身的退出状态码\n  $$ 脚本自身的PID\n  "});})();